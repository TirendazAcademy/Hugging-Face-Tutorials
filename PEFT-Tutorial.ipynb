{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U accelerate peft transformers datasets bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T11:36:52.889814Z","iopub.execute_input":"2023-12-07T11:36:52.890208Z","iopub.status.idle":"2023-12-07T11:37:22.016028Z","shell.execute_reply.started":"2023-12-07T11:36:52.890175Z","shell.execute_reply":"2023-12-07T11:37:22.014981Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:37:22.017991Z","iopub.execute_input":"2023-12-07T11:37:22.018284Z","iopub.status.idle":"2023-12-07T11:37:27.587591Z","shell.execute_reply.started":"2023-12-07T11:37:22.018254Z","shell.execute_reply":"2023-12-07T11:37:27.586823Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:37:27.588714Z","iopub.execute_input":"2023-12-07T11:37:27.589196Z","iopub.status.idle":"2023-12-07T11:37:27.595780Z","shell.execute_reply.started":"2023-12-07T11:37:27.589161Z","shell.execute_reply":"2023-12-07T11:37:27.594973Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nfrom peft import get_peft_model\n\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:37:27.597730Z","iopub.execute_input":"2023-12-07T11:37:27.597989Z","iopub.status.idle":"2023-12-07T11:38:34.019346Z","shell.execute_reply.started":"2023-12-07T11:37:27.597966Z","shell.execute_reply":"2023-12-07T11:38:34.018095Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d9ea75302b4d39b32b827b77671709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f21bf593454b6abe79f3529fd38015"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de1689269884a2cba414519bbb6291c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8fdb198d3d7433d9229cd8b7d860d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a546eb70d7c4f82bfa0d9f6f5eb048a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff7318dc91f4fbb8ae413894d5d026a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29dc04b3f8724c6183e277c70e74a274"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"llama-2-7b-chat-guanaco\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:38:34.020860Z","iopub.execute_input":"2023-12-07T11:38:34.021648Z","iopub.status.idle":"2023-12-07T11:38:34.392649Z","shell.execute_reply.started":"2023-12-07T11:38:34.021603Z","shell.execute_reply":"2023-12-07T11:38:34.391793Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:38:34.393900Z","iopub.execute_input":"2023-12-07T11:38:34.394333Z","iopub.status.idle":"2023-12-07T11:38:35.530162Z","shell.execute_reply.started":"2023-12-07T11:38:34.394306Z","shell.execute_reply":"2023-12-07T11:38:35.528977Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:38:35.531603Z","iopub.execute_input":"2023-12-07T11:38:35.532006Z","iopub.status.idle":"2023-12-07T11:38:39.549392Z","shell.execute_reply.started":"2023-12-07T11:38:35.531970Z","shell.execute_reply":"2023-12-07T11:38:39.548180Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"model.push_to_hub(\"llama-2-7b-chat-guanaco\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:38:39.550990Z","iopub.execute_input":"2023-12-07T11:38:39.551319Z","iopub.status.idle":"2023-12-07T11:39:21.170243Z","shell.execute_reply.started":"2023-12-07T11:38:39.551288Z","shell.execute_reply":"2023-12-07T11:39:21.169405Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6489b57eb8431b8715018256ed0e69"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Tirendaz/llama-2-7b-chat-guanaco/commit/7ce2ce63b6b4fdda1a795820498e995ee95bb2d4', commit_message='Upload model', commit_description='', oid='7ce2ce63b6b4fdda1a795820498e995ee95bb2d4', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom peft import PeftModel\n\npeft_model = \"Tirendaz/llama-2-7b-chat-guanaco\"\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\nmodel = PeftModel.from_pretrained(base_model, peft_model)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:39:21.171441Z","iopub.execute_input":"2023-12-07T11:39:21.171710Z","iopub.status.idle":"2023-12-07T11:39:34.665181Z","shell.execute_reply.started":"2023-12-07T11:39:21.171686Z","shell.execute_reply":"2023-12-07T11:39:34.664381Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae72248637a4915a611f7ff0da1499b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d51d91b20e64e879c639a104ebef816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"774bc853c6cf495c86c68bf1328870a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4db373182ea435fbaa5f90f59178039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f0fe5b5fee546398281a13551e4e81a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6336167116a54781bda92d82a68707f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e2cd069ec6c478fbea8a8e6487e252e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932dec41dd0a44908297401e57e6cb64"}},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(\"cuda\")\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:39:34.667560Z","iopub.execute_input":"2023-12-07T11:39:34.667865Z","iopub.status.idle":"2023-12-07T11:39:34.699783Z","shell.execute_reply.started":"2023-12-07T11:39:34.667839Z","shell.execute_reply":"2023-12-07T11:39:34.698888Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): LlamaRMSNorm()\n            (post_attention_layernorm): LlamaRMSNorm()\n          )\n        )\n        (norm): LlamaRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"prompt = 'I liked \"Breaking Bad\". Suggest other series I might like.'\ninputs = tokenizer(prompt, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:41:20.448519Z","iopub.execute_input":"2023-12-07T11:41:20.449423Z","iopub.status.idle":"2023-12-07T11:41:20.454156Z","shell.execute_reply.started":"2023-12-07T11:41:20.449377Z","shell.execute_reply":"2023-12-07T11:41:20.452920Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"generated_ids = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=200)\ndecoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-07T11:41:24.438942Z","iopub.execute_input":"2023-12-07T11:41:24.439311Z","iopub.status.idle":"2023-12-07T11:41:40.308872Z","shell.execute_reply.started":"2023-12-07T11:41:24.439281Z","shell.execute_reply":"2023-12-07T11:41:40.307881Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"I liked \"Breaking Bad\". Suggest other series I might like. Unterscheidung between \"Breaking Bad\" and \"Better Call Saul\"\n\nIf you enjoyed \"Breaking Bad,\" here are some other series you might like:\n\n1. \"The Sopranos\" - This HBO series is a crime drama that follows the life of Tony Soprano, a New Jersey mob boss, as he navigates the criminal underworld and deals with personal and family issues.\n2. \"The Wire\" - This HBO series explores the drug trade in Baltimore from multiple perspectives, including law enforcement, drug dealers, and politicians. It's known for its gritty realism and complex characters.\n3. \"Narcos\" - This Netflix series tells the true story of Pablo Escobar, the infamous Colombian drug lord, and the DEA agents who hunted him down.\n4. \"Peaky Blinders\" - This BBC series\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}