{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-14T07:56:14.696916Z","iopub.execute_input":"2023-11-14T07:56:14.697205Z","iopub.status.idle":"2023-11-14T07:57:02.968516Z","shell.execute_reply.started":"2023-11-14T07:56:14.697178Z","shell.execute_reply":"2023-11-14T07:57:02.967373Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_path=\"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"","metadata":{"execution":{"iopub.status.busy":"2023-11-14T07:58:25.966214Z","iopub.execute_input":"2023-11-14T07:58:25.966871Z","iopub.status.idle":"2023-11-14T07:58:25.971423Z","shell.execute_reply.started":"2023-11-14T07:58:25.966833Z","shell.execute_reply":"2023-11-14T07:58:25.970503Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:00:19.878354Z","iopub.execute_input":"2023-11-14T08:00:19.879116Z","iopub.status.idle":"2023-11-14T08:00:25.523427Z","shell.execute_reply.started":"2023-11-14T08:00:19.879080Z","shell.execute_reply":"2023-11-14T08:00:25.522513Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:01:05.621508Z","iopub.execute_input":"2023-11-14T08:01:05.622807Z","iopub.status.idle":"2023-11-14T08:01:05.639305Z","shell.execute_reply.started":"2023-11-14T08:01:05.622769Z","shell.execute_reply":"2023-11-14T08:01:05.638513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    torch_dtype = torch.bfloat16,\n    device_map = \"auto\",\n    trust_remote_code = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:03:11.636260Z","iopub.execute_input":"2023-11-14T08:03:11.636692Z","iopub.status.idle":"2023-11-14T08:05:33.829656Z","shell.execute_reply.started":"2023-11-14T08:03:11.636659Z","shell.execute_reply":"2023-11-14T08:05:33.828711Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bb1ea44079404d999bcb6a24a2d9ac"}},"metadata":{}}]},{"cell_type":"code","source":"messages = [{\n    \"role\":\"user\",\n    \"content\": \"Can you tell us 3 cities to visit in Turkey\"\n}]","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:11:11.955419Z","iopub.execute_input":"2023-11-14T08:11:11.956460Z","iopub.status.idle":"2023-11-14T08:11:11.960583Z","shell.execute_reply.started":"2023-11-14T08:11:11.956426Z","shell.execute_reply":"2023-11-14T08:11:11.959576Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer.apply_chat_template(messages, tokenize=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:12:17.523502Z","iopub.execute_input":"2023-11-14T08:12:17.523917Z","iopub.status.idle":"2023-11-14T08:12:17.572516Z","shell.execute_reply.started":"2023-11-14T08:12:17.523889Z","shell.execute_reply":"2023-11-14T08:12:17.571653Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'<s>[INST] Can you tell us 3 cities to visit in Turkey [/INST]'"},"metadata":{}}]},{"cell_type":"code","source":"model_inputs = tokenizer.apply_chat_template(messages, \n                                             return_tensors = \"pt\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:14:04.861984Z","iopub.execute_input":"2023-11-14T08:14:04.862399Z","iopub.status.idle":"2023-11-14T08:14:04.868278Z","shell.execute_reply.started":"2023-11-14T08:14:04.862358Z","shell.execute_reply":"2023-11-14T08:14:04.867325Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:14:29.654610Z","iopub.execute_input":"2023-11-14T08:14:29.655115Z","iopub.status.idle":"2023-11-14T08:14:29.665739Z","shell.execute_reply.started":"2023-11-14T08:14:29.655071Z","shell.execute_reply":"2023-11-14T08:14:29.664694Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[    1,   733, 16289, 28793,  2418,   368,  1912,   592, 28705, 28770,\n          9245,   298,  3251,   297, 17915,   733, 28748, 16289, 28793]])"},"metadata":{}}]},{"cell_type":"code","source":"generated_ids = model.generate(\n    model_inputs,\n    max_new_tokens = 1000,\n    do_sample = True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:16:13.313636Z","iopub.execute_input":"2023-11-14T08:16:13.314389Z","iopub.status.idle":"2023-11-14T08:16:41.927745Z","shell.execute_reply.started":"2023-11-14T08:16:13.314355Z","shell.execute_reply":"2023-11-14T08:16:41.926709Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1671: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"decoded = tokenizer.batch_decode(generated_ids)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:17:28.764906Z","iopub.execute_input":"2023-11-14T08:17:28.765278Z","iopub.status.idle":"2023-11-14T08:17:28.770799Z","shell.execute_reply.started":"2023-11-14T08:17:28.765247Z","shell.execute_reply":"2023-11-14T08:17:28.769724Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:17:51.173959Z","iopub.execute_input":"2023-11-14T08:17:51.174294Z","iopub.status.idle":"2023-11-14T08:17:51.179010Z","shell.execute_reply.started":"2023-11-14T08:17:51.174268Z","shell.execute_reply":"2023-11-14T08:17:51.178228Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<s> [INST] Can you tell us 3 cities to visit in Turkey [/INST] 1. Istanbul: Located on both Europe and Asia, Istanbul is the capital of Turkey and a major cultural center, known for its architecture, art, music, and cuisine.\n\n2. Ank numbers: A beautiful coastal city located near the Mediterranean Sea, Antalya is known for its stunning beaches, crystal-clear waters, and historic sites such as the Taurus Mountains, Perge, and Aspendos.\n\n3. Ephesus: Located near the city of Sel√ßuk, Ephesus is a UNESCO-listed site, known for its well-preserved ruins and ancient history dating back to 550 BC. The site features the Temple of Artemis, the Great Theater, and the impressive Library of Celsius.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [{\n    \"role\": \"user\", \n    \"content\": \"Act as a gourmet chef. I have a friend coming over who is a vegetarian. \\\n    I want to impress my friend with a special vegetarian dish. \\\n    What do you recommend? \\\n    Give me two options, along with the whole recipe for each\"\n}]","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:19:57.874622Z","iopub.execute_input":"2023-11-14T08:19:57.875027Z","iopub.status.idle":"2023-11-14T08:19:57.880243Z","shell.execute_reply.started":"2023-11-14T08:19:57.874997Z","shell.execute_reply":"2023-11-14T08:19:57.879195Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\n\ngenerated_ids = model.generate(\n    model_inputs,\n    max_new_tokens = 1000,\n    do_sample = True,\n)\n\ndecoded = tokenizer.batch_decode(generated_ids)\n\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:21:40.194363Z","iopub.execute_input":"2023-11-14T08:21:40.195096Z","iopub.status.idle":"2023-11-14T08:22:37.234725Z","shell.execute_reply.started":"2023-11-14T08:21:40.195061Z","shell.execute_reply":"2023-11-14T08:22:37.233589Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1671: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"<s> [INST] Act as a gourmet chef. I have a friend coming over who is a vegetarian.     I want to impress my friend with a special vegetarian dish.     What do you recommend?     Give me two options, along with the whole recipe for each [/INST] As a gourmet chef, I would be happy to help you impress your friend with a special vegetarian dish. Here are two options that I recommend:\n\nOption 1: Eggplant Parmesan\n\nIngredients:\n\n* 2 large eggplants\n* 1/2 cup all-purpose flour\n* 1 egg, beaten\n* 2 cups panko bread crumbs\n* 1/2 cup grated Parmesan cheese\n* 1 teaspoon dried basil\n* 1 teaspoon dried oregano\n* 1/2 teaspoon salt\n* 1/4 teaspoon black pepper\n* 1/4 cup olive oil\n* 2 cups marinara sauce\n* 1 cup shredded mozzarella cheese\n* Fresh basil leaves, for garnish\n\nInstructions:\n\n1. Preheat the oven to 375¬∞F (190¬∞C).\n2. Slice the eggplants lengthwise into 1/2-inch-thick slices.\n3. Season salt on both sides, then salt both sides again lightly.\n4. Dip the eggplant slices in flour to coat, then in the beaten egg, then in the panko mixture.\n5. Heat the olive oil in a large oven-safe skillet over medium heat.\n6. Add the panko-coated eggplant slices to the skillet, pressing them lightly into the pan.\n7. Bake the panko-coated eggplant slices in the preheated oven for 20-25 minutes, until they are golden brown and crispy.\n8. Spread the marinara sauce over the panko-coated eggplant slices, and top with the shredded mozzarella cheese.\n9. Bake for an additional 10-15 minutes, until the cheese is melted and bubbly.\n10 wyn garnish with fresh basil leaves and serve immediately.\n\nOption 2: Quinoa Stuffed Bell Peppers\n\nIngredients:\n\n* 4 large bell peppers\n* 1 cup quinoa\n* 2 cups vegetable broth\n* 1 teaspoon ground cumin\n* 1 teaspoon dried oregano\n* 1/2 teaspoon paprika\n* 1/2 teaspoon salt\n* 1/4 teaspoon black pepper\n* 1/2 cup canned black beans, drained and rinsed\n* 1/2 cup canned corn, drained\n* 1/2 cup diced cherry tomatoes\n* 1/2 cup chopped fresh cilantro\n* Juice of 1 lime\n* 1 tablespoon olive oil\n* 1 clove garlic, minced\n* 1/2 teaspoon cayenne pepper (optional)\n\nInstructions:\n\n1. Preheat the oven to 375¬∞F (190¬∞C).\n2. Cut the tops off the bell peppers and remove the seeds and membranes.\n3. Rinse the quinoa in a fine mesh strainer, then transfer to a medium saucepan with the vegetable broth.\n4. Bring the vegetable broth to a boil, then reduce the heat to low and cover.\n5. Let the quinoa simmer for 18-20 minutes, until it is cooked through.\n6. In a large bowl, mix the cooked quinoa, black beans, corn, cherry tomatoes, cilantro, lime juice, olive oil, minced garlic, cayenne pepper (optional), cumin, dried oregano, paprika, salt, and black pepper.\n7. Spoon the quinoa mixture</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [{\n    \"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"\n}]\nmodel_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\ngenerated_ids = model.generate(\n    model_inputs,\n    max_new_tokens = 1000,\n    do_sample = True,\n)\ndecoded = tokenizer.batch_decode(generated_ids)\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:25:13.685193Z","iopub.execute_input":"2023-11-14T08:25:13.685591Z","iopub.status.idle":"2023-11-14T08:25:19.079514Z","shell.execute_reply.started":"2023-11-14T08:25:13.685560Z","shell.execute_reply":"2023-11-14T08:25:19.078296Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s> [INST] How many helicopters can a human eat in one sitting? [/INST] It is not possible for a human to eat a helicopter in one sitting, as helicopters are not designed to be consumed by humans. They are built for transportation and aerial maneuverability, not for consumption. Additionally, helicopters are made of metal and other materials that are not biodegradable, which would make them harmful if ingested.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"What fascinates you about AI?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fascinated \\\n    by AI's data analysis and prediction abilities. \\\n    It has the potential to revolutionize industries and improve problem-solving.\"},\n    {\"role\": \"user\", \"content\": \"Should people be afraid of AI?\"}\n]\nmodel_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\ngenerated_ids = model.generate(\n    model_inputs,\n    max_new_tokens = 1000,\n    do_sample = True,\n)\ndecoded = tokenizer.batch_decode(generated_ids)\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:28:05.644611Z","iopub.execute_input":"2023-11-14T08:28:05.645596Z","iopub.status.idle":"2023-11-14T08:28:10.683005Z","shell.execute_reply.started":"2023-11-14T08:28:05.645559Z","shell.execute_reply":"2023-11-14T08:28:10.682093Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s> [INST] What fascinates you about AI? [/INST]I'm fascinated     by AI's data analysis and prediction abilities.     It has the potential to revolutionize industries and improve problem-solving.</s>  [INST] Should people be afraid of AI? [/INST] People may be afraid of certain AI capabilities, such as autonomous weapons or invasive surveillance systems. However, overall, I believe that AI, like any technology, can be positive or negative depending on how it's used and developed. It's important for people to stay informed about AI developments and to encourage responsible AI development and usage.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"T√ºrkiye'de en fazla ziyaret edilen 3 ≈üehir hangidir?\"},\n]\nmodel_inputs = tokenizer.apply_chat_template(messages,return_tensors = \"pt\")\ngenerated_ids = model.generate(\n    model_inputs,\n    max_new_tokens = 1000,\n    do_sample = True,\n)\ndecoded = tokenizer.batch_decode(generated_ids)\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T08:30:05.833518Z","iopub.execute_input":"2023-11-14T08:30:05.834411Z","iopub.status.idle":"2023-11-14T08:30:07.711400Z","shell.execute_reply.started":"2023-11-14T08:30:05.834378Z","shell.execute_reply":"2023-11-14T08:30:07.710245Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<s> [INST] T√ºrkiye'de en fazla ziyaret edilen 3 ≈üehir hangidir? [/INST] 1. ƒ∞stanbul\n2. Ankara\n3. Antalya</s>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's connect [YouTube](http://youtube.com/tirendazacademy) | [Medium](http://tirendazacademy.medium.com) | [X](http://x.com/tirendazacademy) | [Linkedin](https://www.linkedin.com/in/tirendaz-academy)","metadata":{}}]}