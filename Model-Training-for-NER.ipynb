{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Loading the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:12:32.488703Z","iopub.execute_input":"2023-10-21T14:12:32.488970Z","iopub.status.idle":"2023-10-21T14:12:46.334711Z","shell.execute_reply.started":"2023-10-21T14:12:32.488944Z","shell.execute_reply":"2023-10-21T14:12:46.333561Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom collections import defaultdict\nfrom datasets import DatasetDict\n\n\nlangs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs= [0.629, 0.229, 0.084, 0.059]\n\npanx_ch = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    for split in ds:\n        panx_ch[lang][split] = (\n            ds[split].shuffle(seed=0).select(range(int(frac*ds[split].num_rows))))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:12:46.336574Z","iopub.execute_input":"2023-10-21T14:12:46.336887Z","iopub.status.idle":"2023-10-21T14:13:26.534026Z","shell.execute_reply.started":"2023-10-21T14:12:46.336862Z","shell.execute_reply":"2023-10-21T14:13:26.533221Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1230ac046fb419980a9505b909950a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da3cceec5044c418457a966fbb3af64"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028b45be0a22412896a65b87346d00d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c72a84cc2dbc48efbd1b54ead85e452b"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b2e93139c143519fceb906a89d38fe"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8199f3f2e5a4fb282ab92e261406474"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c3954728ec04123bf2bee3b87c96057"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's take a look at the number of training examples of all datasets:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"number of training examples\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:26.535470Z","iopub.execute_input":"2023-10-21T14:13:26.536442Z","iopub.status.idle":"2023-10-21T14:13:26.563872Z","shell.execute_reply.started":"2023-10-21T14:13:26.536404Z","shell.execute_reply":"2023-10-21T14:13:26.563131Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                de    fr    it    en\nnumber of training examples  12580  4580  1680  1180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>number of training examples</th>\n      <td>12580</td>\n      <td>4580</td>\n      <td>1680</td>\n      <td>1180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Understanding the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"element = panx_ch[\"de\"][\"train\"][0]\n\nfor key, value in element.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:26.565778Z","iopub.execute_input":"2023-10-21T14:13:26.566043Z","iopub.status.idle":"2023-10-21T14:13:26.572546Z","shell.execute_reply.started":"2023-10-21T14:13:26.566020Z","shell.execute_reply":"2023-10-21T14:13:26.571642Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\nner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\nlangs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n","output_type":"stream"}]},{"cell_type":"code","source":"for key, value in panx_ch[\"de\"][\"train\"].features.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:26.573782Z","iopub.execute_input":"2023-10-21T14:13:26.574074Z","iopub.status.idle":"2023-10-21T14:13:26.584677Z","shell.execute_reply.started":"2023-10-21T14:13:26.574036Z","shell.execute_reply":"2023-10-21T14:13:26.583709Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\nner_tags: Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\nlangs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:26.585594Z","iopub.execute_input":"2023-10-21T14:13:26.585826Z","iopub.status.idle":"2023-10-21T14:13:26.596309Z","shell.execute_reply.started":"2023-10-21T14:13:26.585805Z","shell.execute_reply":"2023-10-21T14:13:26.595257Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Data Preprocessing </div></b>","metadata":{}},{"cell_type":"code","source":"def create_tag_names(batch):\n    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n\npanx_de = panx_ch[\"de\"].map(create_tag_names)\nde_example = panx_de[\"train\"][0]\npd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:26.597435Z","iopub.execute_input":"2023-10-21T14:13:26.597787Z","iopub.status.idle":"2023-10-21T14:13:30.936413Z","shell.execute_reply.started":"2023-10-21T14:13:26.597741Z","shell.execute_reply":"2023-10-21T14:13:30.935408Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12580 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2259ca1f5f94a0db9e6f6e7021fc17e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b899a7dc6811405aa38296d1d8246133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab3e70baee334809a44c24ebd9699012"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nTokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nTags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n\n                  9        10 11  \nTokens  Woiwodschaft  Pommern  .  \nTags           B-LOC    I-LOC  O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\nsplit2freqs = defaultdict(Counter)\n\nfor split, dataset in panx_de.items():\n    for row in dataset[\"ner_tags_str\"]:\n        for tag in row:\n            if tag.startswith(\"B\"):\n                tag_type = tag.split(\"-\")[1]\n                split2freqs[split][tag_type] +=1\n\npd.DataFrame.from_dict(split2freqs, orient = \"index\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:30.937577Z","iopub.execute_input":"2023-10-21T14:13:30.937894Z","iopub.status.idle":"2023-10-21T14:13:31.438420Z","shell.execute_reply.started":"2023-10-21T14:13:30.937868Z","shell.execute_reply":"2023-10-21T14:13:31.437461Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Bert Tokenizer vs XLM-R Tokenizer </div></b>","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\nxlmr_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:31.439796Z","iopub.execute_input":"2023-10-21T14:13:31.440221Z","iopub.status.idle":"2023-10-21T14:13:35.638083Z","shell.execute_reply.started":"2023-10-21T14:13:31.440162Z","shell.execute_reply":"2023-10-21T14:13:35.637182Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8710c4a98bae4f2489b83c7dc3b38317"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2e954d31704c74aa7cc53f4aa999cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887c7d2610dd43fd8dc557376de115c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7722fda9393d46689f7155f931e8f92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f7f194037146ffb7f6cdfc46b2bae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7518c32f01a4ff3a0b3cf4b16b860df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6abb8e77d2114e4dbf98186deae3c3f2"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"Tim Sparrow lives San Diego!\"\n\nbert_tokens = bert_tokenizer(text).tokens()\nxlmr_tokens = xlmr_tokenizer(text).tokens()\n\npd.DataFrame([bert_tokens, xlmr_tokens], index = [\"BERT\",\"XLM-R\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:35.641710Z","iopub.execute_input":"2023-10-21T14:13:35.642152Z","iopub.status.idle":"2023-10-21T14:13:35.662691Z","shell.execute_reply.started":"2023-10-21T14:13:35.642126Z","shell.execute_reply":"2023-10-21T14:13:35.661618Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           0     1      2       3       4     5       6  7      8\nBERT   [CLS]   Tim    Spa  ##rrow   lives   San   Diego  !  [SEP]\nXLM-R    <s>  ▁Tim  ▁Spar     row  ▁lives  ▁San  ▁Diego  !   </s>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BERT</th>\n      <td>[CLS]</td>\n      <td>Tim</td>\n      <td>Spa</td>\n      <td>##rrow</td>\n      <td>lives</td>\n      <td>San</td>\n      <td>Diego</td>\n      <td>!</td>\n      <td>[SEP]</td>\n    </tr>\n    <tr>\n      <th>XLM-R</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import XLMRobertaForTokenClassification\nimport torch\n\nxlmr_model_name = \"xlm-roberta-base\"\nindex2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}\nnum_labels = tags.num_classes\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nxlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n    xlmr_model_name,\n    num_labels = num_labels,\n    id2label=index2tag,\n    label2id=tag2index\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:13:35.663952Z","iopub.execute_input":"2023-10-21T14:13:35.664583Z","iopub.status.idle":"2023-10-21T14:14:01.354328Z","shell.execute_reply.started":"2023-10-21T14:13:35.664549Z","shell.execute_reply":"2023-10-21T14:14:01.353259Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805f7f45d74348b09da4ae2cc797d183"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ids = xlmr_tokenizer.encode(text, return_tensors = \"pt\")\n\npd.DataFrame([xlmr_tokens, input_ids[0].numpy()],  index = [\"Tokens\", \"Input IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:01.355697Z","iopub.execute_input":"2023-10-21T14:14:01.356075Z","iopub.status.idle":"2023-10-21T14:14:01.372250Z","shell.execute_reply.started":"2023-10-21T14:14:01.356040Z","shell.execute_reply":"2023-10-21T14:14:01.371286Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             0      1      2      3       4     5       6   7     8\nTokens     <s>   ▁Tim  ▁Spar    row  ▁lives  ▁San  ▁Diego   !  </s>\nInput IDs    0  13320  37456  15555   60742  1735   59826  38     2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>13320</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>60742</td>\n      <td>1735</td>\n      <td>59826</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"outputs = xlmr_model(input_ids.to(device)).logits\n\npredictions = torch.argmax(outputs, dim=-1)\n\npreds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n\npd.DataFrame( [xlmr_tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:01.373789Z","iopub.execute_input":"2023-10-21T14:14:01.374189Z","iopub.status.idle":"2023-10-21T14:14:03.932576Z","shell.execute_reply.started":"2023-10-21T14:14:01.374151Z","shell.execute_reply":"2023-10-21T14:14:03.931611Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"            0      1      2      3       4      5       6      7      8\nTokens    <s>   ▁Tim  ▁Spar    row  ▁lives   ▁San  ▁Diego      !   </s>\nTags    I-PER  I-ORG  I-ORG  I-ORG   B-PER  I-ORG   I-ORG  I-ORG  I-PER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>B-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tag_text(text, tags, model, tokenizer):\n    tokens = tokenizer(text).tokens()\n    input_ids = xlmr_tokenizer.encode(\n        text, return_tensors = \"pt\").to(device)\n    outputs = model(input_ids)[0]\n    predictions = torch.argmax(outputs, dim=2)\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:03.933949Z","iopub.execute_input":"2023-10-21T14:14:03.934335Z","iopub.status.idle":"2023-10-21T14:14:03.941139Z","shell.execute_reply.started":"2023-10-21T14:14:03.934300Z","shell.execute_reply":"2023-10-21T14:14:03.940091Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Tokenizer for NER Analysis </div></b>","metadata":{}},{"cell_type":"code","source":"words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n\npd.DataFrame([words, labels], index = [\"words\", \"labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:03.942401Z","iopub.execute_input":"2023-10-21T14:14:03.942798Z","iopub.status.idle":"2023-10-21T14:14:03.962164Z","shell.execute_reply.started":"2023-10-21T14:14:03.942763Z","shell.execute_reply":"2023-10-21T14:14:03.961097Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nwords   2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nlabels      0           0   0    0         5      6   0    0           5   \n\n                  9        10 11  \nwords   Woiwodschaft  Pommern  .  \nlabels             5        6  0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>words</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(de_example[\"tokens\"],is_split_into_words=True)\n\ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n\npd.DataFrame([tokens], index=[\"Tokens\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:03.963402Z","iopub.execute_input":"2023-10-21T14:14:03.963671Z","iopub.status.idle":"2023-10-21T14:14:03.987917Z","shell.execute_reply.started":"2023-10-21T14:14:03.963646Z","shell.execute_reply":"2023-10-21T14:14:03.986986Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         0       1           2  3    4     5     6   7    8      9   ...   15  \\\nTokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n\n       16   17      18   19    20 21 22 23    24  \nTokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n\n[1 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = tokenized_input.word_ids()\n\npd.DataFrame([tokens, word_ids], index = [\"Tokens\",\"Word IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:03.988963Z","iopub.execute_input":"2023-10-21T14:14:03.989265Z","iopub.status.idle":"2023-10-21T14:14:04.010651Z","shell.execute_reply.started":"2023-10-21T14:14:03.989239Z","shell.execute_reply":"2023-10-21T14:14:04.009837Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            0       1           2  3    4     5     6   7    8      9   ...  \\\nTokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \nWord IDs  None       0           1  1    2     3     4   4    4      5  ...   \n\n           15 16   17      18   19    20  21  22  23    24  \nTokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \nWord IDs    9  9    9       9   10    10  10  11  11  None  \n\n[2 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"previous_word_idx = None\nlabel_ids = []\nfor word_idx in word_ids:\n    if word_idx is None or word_idx == previous_word_idx:\n        label_ids.append(-100)\n    elif word_idx != previous_word_idx:\n        label_ids.append(labels[word_idx])\n    previous_word_idx = word_idx\n\nlabels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n\nindex = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\npd.DataFrame([tokens, word_ids, label_ids, labels], index = index)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:04.011885Z","iopub.execute_input":"2023-10-21T14:14:04.012182Z","iopub.status.idle":"2023-10-21T14:14:04.040076Z","shell.execute_reply.started":"2023-10-21T14:14:04.012150Z","shell.execute_reply":"2023-10-21T14:14:04.039116Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"             0       1           2     3    4     5      6     7     8   \\\nTokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \nWord IDs   None       0           1     1    2     3      4     4     4   \nLabel IDs  -100       0           0  -100    0     0      5  -100  -100   \nLabels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n\n              9   ...     15    16    17      18     19    20    21  22    23  \\\nTokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \nWord IDs       5  ...      9     9     9       9     10    10    10  11    11   \nLabel IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \nLabels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n\n             24  \nTokens     </s>  \nWord IDs   None  \nLabel IDs  -100  \nLabels      IGN  \n\n[4 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>Label IDs</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>...</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], \n                                     truncation = True,\n                                     is_split_into_words = True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs        ","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:04.041356Z","iopub.execute_input":"2023-10-21T14:14:04.041623Z","iopub.status.idle":"2023-10-21T14:14:04.048879Z","shell.execute_reply.started":"2023-10-21T14:14:04.041599Z","shell.execute_reply":"2023-10-21T14:14:04.047817Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels,\n                     batched=True,\n                     remove_columns=[\"langs\", \"ner_tags\", \"tokens\"])\n\npanx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:04.050119Z","iopub.execute_input":"2023-10-21T14:14:04.050454Z","iopub.status.idle":"2023-10-21T14:14:07.288068Z","shell.execute_reply.started":"2023-10-21T14:14:04.050417Z","shell.execute_reply":"2023-10-21T14:14:07.287110Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a789447d1945baa6c43b23577cd047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575cb98fffda43688e46f0e78d80ac0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc27aac8af94c7dac92d48e5911e03e"}},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Model Metrics </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q seqeval","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:07.289339Z","iopub.execute_input":"2023-10-21T14:14:07.289638Z","iopub.status.idle":"2023-10-21T14:14:25.475564Z","shell.execute_reply.started":"2023-10-21T14:14:07.289599Z","shell.execute_reply":"2023-10-21T14:14:25.474370Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\ny_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\ny_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\n\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.477067Z","iopub.execute_input":"2023-10-21T14:14:25.477359Z","iopub.status.idle":"2023-10-21T14:14:25.752223Z","shell.execute_reply.started":"2023-10-21T14:14:25.477333Z","shell.execute_reply":"2023-10-21T14:14:25.750956Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        MISC       0.00      0.00      0.00         1\n         PER       1.00      1.00      1.00         1\n\n   micro avg       0.50      0.50      0.50         2\n   macro avg       0.50      0.50      0.50         2\nweighted avg       0.50      0.50      0.50         2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef align_predictions(predictions, label_ids):\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_len):\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n        \n        labels_list.append(example_labels)  \n        preds_list.append(example_preds) \n    \n    return preds_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.753715Z","iopub.execute_input":"2023-10-21T14:14:25.754068Z","iopub.status.idle":"2023-10-21T14:14:25.761646Z","shell.execute_reply.started":"2023-10-21T14:14:25.754035Z","shell.execute_reply":"2023-10-21T14:14:25.760510Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Model Training </div></b>","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.762838Z","iopub.execute_input":"2023-10-21T14:14:25.763123Z","iopub.status.idle":"2023-10-21T14:14:25.779770Z","shell.execute_reply.started":"2023-10-21T14:14:25.763099Z","shell.execute_reply":"2023-10-21T14:14:25.778871Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"num_epochs= 3\nbatch_size = 24\nlogging_steps = len(panx_de_encoded[\"train\"]) // batch_size\nmodel_name = \"multilingual-xlm-roberta-for-ner\"","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.780815Z","iopub.execute_input":"2023-10-21T14:14:25.781086Z","iopub.status.idle":"2023-10-21T14:14:25.792252Z","shell.execute_reply.started":"2023-10-21T14:14:25.781064Z","shell.execute_reply":"2023-10-21T14:14:25.791426Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir = model_name,\n    log_level = \"error\",\n    num_train_epochs = num_epochs,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    evaluation_strategy = \"epoch\", \n    save_steps = 1e6,\n    weight_decay = 0.01,\n    logging_steps = logging_steps,\n    report_to= \"none\",\n    push_to_hub = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.793447Z","iopub.execute_input":"2023-10-21T14:14:25.793832Z","iopub.status.idle":"2023-10-21T14:14:25.805921Z","shell.execute_reply.started":"2023-10-21T14:14:25.793801Z","shell.execute_reply":"2023-10-21T14:14:25.804999Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.807117Z","iopub.execute_input":"2023-10-21T14:14:25.808028Z","iopub.status.idle":"2023-10-21T14:14:25.840049Z","shell.execute_reply.started":"2023-10-21T14:14:25.807997Z","shell.execute_reply":"2023-10-21T14:14:25.839239Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946a4d1a2f67451c892c7a8f03a64f7d"}},"metadata":{}}]},{"cell_type":"code","source":"from seqeval.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.846689Z","iopub.execute_input":"2023-10-21T14:14:25.847018Z","iopub.status.idle":"2023-10-21T14:14:25.851623Z","shell.execute_reply.started":"2023-10-21T14:14:25.846988Z","shell.execute_reply":"2023-10-21T14:14:25.850655Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(\n                        eval_pred.predictions, eval_pred.label_ids)\n    return {\"f1\": f1_score(y_true, y_pred)}","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.852748Z","iopub.execute_input":"2023-10-21T14:14:25.853086Z","iopub.status.idle":"2023-10-21T14:14:25.862950Z","shell.execute_reply.started":"2023-10-21T14:14:25.853056Z","shell.execute_reply":"2023-10-21T14:14:25.861931Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:25.864138Z","iopub.execute_input":"2023-10-21T14:14:25.864475Z","iopub.status.idle":"2023-10-21T14:14:26.004771Z","shell.execute_reply.started":"2023-10-21T14:14:25.864443Z","shell.execute_reply":"2023-10-21T14:14:26.003987Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:26.006022Z","iopub.execute_input":"2023-10-21T14:14:26.006396Z","iopub.status.idle":"2023-10-21T14:14:26.010501Z","shell.execute_reply.started":"2023-10-21T14:14:26.006364Z","shell.execute_reply":"2023-10-21T14:14:26.009504Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return xlmr_model","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:26.011789Z","iopub.execute_input":"2023-10-21T14:14:26.012063Z","iopub.status.idle":"2023-10-21T14:14:26.022499Z","shell.execute_reply.started":"2023-10-21T14:14:26.012039Z","shell.execute_reply":"2023-10-21T14:14:26.021747Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:14:26.023597Z","iopub.execute_input":"2023-10-21T14:14:26.023927Z","iopub.status.idle":"2023-10-21T14:14:26.054618Z","shell.execute_reply.started":"2023-10-21T14:14:26.023884Z","shell.execute_reply":"2023-10-21T14:14:26.053760Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model_init = model_init,\n    args = training_args,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics,\n    train_dataset = panx_de_encoded[\"train\"],\n    eval_dataset = panx_de_encoded[\"validation\"],\n    tokenizer = xlmr_tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:15:06.945726Z","iopub.execute_input":"2023-10-21T14:15:06.946445Z","iopub.status.idle":"2023-10-21T14:15:07.047383Z","shell.execute_reply.started":"2023-10-21T14:15:06.946410Z","shell.execute_reply":"2023-10-21T14:15:07.046232Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.push_to_hub(commit_message=\"Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:15:10.447523Z","iopub.execute_input":"2023-10-21T14:15:10.447894Z","iopub.status.idle":"2023-10-21T14:24:19.652038Z","shell.execute_reply.started":"2023-10-21T14:15:10.447863Z","shell.execute_reply":"2023-10-21T14:24:19.651053Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='789' max='789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [789/789 08:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.160884</td>\n      <td>0.821622</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.215200</td>\n      <td>0.139543</td>\n      <td>0.849155</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.215200</td>\n      <td>0.137564</td>\n      <td>0.858523</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f16f602de9024994ae0ce9fc98ce831d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c65386927934468aa200fd731b6e4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ac691164394bc8815b46dc4c1f04ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a07f3593d94a1db86a2608ddd01c62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f28028eca44a84b050dfbb1414d6f8"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Tirendaz/multilingual-xlm-roberta-for-ner/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"text_de = \"tim Dean ist ein Informatiker bei Google in Kalifornien\"","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:30:00.433002Z","iopub.execute_input":"2023-10-21T14:30:00.433895Z","iopub.status.idle":"2023-10-21T14:30:00.438112Z","shell.execute_reply.started":"2023-10-21T14:30:00.433859Z","shell.execute_reply":"2023-10-21T14:30:00.437084Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"tag_text(text_de, tags, trainer.model, xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T14:31:43.512803Z","iopub.execute_input":"2023-10-21T14:31:43.513190Z","iopub.status.idle":"2023-10-21T14:31:43.552073Z","shell.execute_reply.started":"2023-10-21T14:31:43.513162Z","shell.execute_reply":"2023-10-21T14:31:43.551102Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"         0      1      2      3     4     5           6    7     8        9   \\\nTokens  <s>   ▁tim    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \nTags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n\n         10          11     12    13  \nTokens  ▁in  ▁Kaliforni     en  </s>  \nTags      O       B-LOC  I-LOC     O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁tim</td>\n      <td>▁De</td>\n      <td>an</td>\n      <td>▁ist</td>\n      <td>▁ein</td>\n      <td>▁Informati</td>\n      <td>ker</td>\n      <td>▁bei</td>\n      <td>▁Google</td>\n      <td>▁in</td>\n      <td>▁Kaliforni</td>\n      <td>en</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}