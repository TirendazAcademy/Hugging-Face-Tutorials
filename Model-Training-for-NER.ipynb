{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Loading the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:05:53.378727Z","iopub.execute_input":"2023-10-19T19:05:53.379107Z","iopub.status.idle":"2023-10-19T19:06:05.549523Z","shell.execute_reply.started":"2023-10-19T19:05:53.379076Z","shell.execute_reply":"2023-10-19T19:06:05.548186Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom collections import defaultdict\nfrom datasets import DatasetDict\n\n\nlangs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs= [0.629, 0.229, 0.084, 0.059]\n\npanx_ch = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    for split in ds:\n        panx_ch[lang][split] = (\n            ds[split].shuffle(seed=0).select(range(int(frac*ds[split].num_rows))))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:06:05.551734Z","iopub.execute_input":"2023-10-19T19:06:05.552176Z","iopub.status.idle":"2023-10-19T19:07:01.600380Z","shell.execute_reply.started":"2023-10-19T19:06:05.552139Z","shell.execute_reply":"2023-10-19T19:07:01.599255Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3448fb406c4bdab0a2f9b9c5ebaab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"485b3045d2cf4171a8941fb7b2b4208c"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec01e02e0504211807cf3c53014e43e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bab65fd1004a4dfda756390c550568b1"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b73bcca4fcd47b49b29b1e0742e3274"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148dc8744bb7462f9bafa1906ef026b1"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61578d61a7bd421dba4954fb3ae47756"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's take a look at the number of training examples of all datasets:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"number of training examples\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:01.601847Z","iopub.execute_input":"2023-10-19T19:07:01.602771Z","iopub.status.idle":"2023-10-19T19:07:01.624524Z","shell.execute_reply.started":"2023-10-19T19:07:01.602738Z","shell.execute_reply":"2023-10-19T19:07:01.623752Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                de    fr    it    en\nnumber of training examples  12580  4580  1680  1180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>number of training examples</th>\n      <td>12580</td>\n      <td>4580</td>\n      <td>1680</td>\n      <td>1180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Understanding the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"element = panx_ch[\"de\"][\"train\"][0]\n\nfor key, value in element.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:01.626215Z","iopub.execute_input":"2023-10-19T19:07:01.627285Z","iopub.status.idle":"2023-10-19T19:07:01.636058Z","shell.execute_reply.started":"2023-10-19T19:07:01.627242Z","shell.execute_reply":"2023-10-19T19:07:01.634987Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\nner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\nlangs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n","output_type":"stream"}]},{"cell_type":"code","source":"for key, value in panx_ch[\"de\"][\"train\"].features.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:01.637572Z","iopub.execute_input":"2023-10-19T19:07:01.637916Z","iopub.status.idle":"2023-10-19T19:07:01.648505Z","shell.execute_reply.started":"2023-10-19T19:07:01.637888Z","shell.execute_reply":"2023-10-19T19:07:01.647439Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\nner_tags: Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\nlangs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:01.649791Z","iopub.execute_input":"2023-10-19T19:07:01.650768Z","iopub.status.idle":"2023-10-19T19:07:01.661756Z","shell.execute_reply.started":"2023-10-19T19:07:01.650726Z","shell.execute_reply":"2023-10-19T19:07:01.660642Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Data Preprocessing </div></b>","metadata":{}},{"cell_type":"code","source":"def create_tag_names(batch):\n    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n\npanx_de = panx_ch[\"de\"].map(create_tag_names)\nde_example = panx_de[\"train\"][0]\npd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:01.663262Z","iopub.execute_input":"2023-10-19T19:07:01.664012Z","iopub.status.idle":"2023-10-19T19:07:05.285293Z","shell.execute_reply.started":"2023-10-19T19:07:01.663984Z","shell.execute_reply":"2023-10-19T19:07:05.284287Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12580 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a4b58737fd404e9804c942ad6a5b61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"053cf92fbee14af7839fc6675f4d294a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2bbbc458d094e6998a3306a6c958534"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nTokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nTags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n\n                  9        10 11  \nTokens  Woiwodschaft  Pommern  .  \nTags           B-LOC    I-LOC  O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\nsplit2freqs = defaultdict(Counter)\n\nfor split, dataset in panx_de.items():\n    for row in dataset[\"ner_tags_str\"]:\n        for tag in row:\n            if tag.startswith(\"B\"):\n                tag_type = tag.split(\"-\")[1]\n                split2freqs[split][tag_type] +=1\n\npd.DataFrame.from_dict(split2freqs, orient = \"index\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:05.287380Z","iopub.execute_input":"2023-10-19T19:07:05.288525Z","iopub.status.idle":"2023-10-19T19:07:05.612308Z","shell.execute_reply.started":"2023-10-19T19:07:05.288485Z","shell.execute_reply":"2023-10-19T19:07:05.611162Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Bert Tokenizer vs XLM-R Tokenizer </div></b>","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\nxlmr_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:05.613555Z","iopub.execute_input":"2023-10-19T19:07:05.613852Z","iopub.status.idle":"2023-10-19T19:07:16.230638Z","shell.execute_reply.started":"2023-10-19T19:07:05.613828Z","shell.execute_reply":"2023-10-19T19:07:16.229374Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e684882c396e47a7b5b1d87ec39b227d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d8281726dd1400e890af154d1129c18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba2b3632e7d41fdabcf6bde95bebc28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70baa8e315d7428a94423a8c6f95194a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93465ff81a84c8b9b29293b198866ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecd6cfc620a04c39a6d962c0f286bdcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"776403c535f74e9f8660e8f7de35a331"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"Tim Sparrow lives San Diego!\"\n\nbert_tokens = bert_tokenizer(text).tokens()\nxlmr_tokens = xlmr_tokenizer(text).tokens()\n\npd.DataFrame([bert_tokens, xlmr_tokens], index = [\"BERT\",\"XLM-R\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:16.234148Z","iopub.execute_input":"2023-10-19T19:07:16.234686Z","iopub.status.idle":"2023-10-19T19:07:16.257006Z","shell.execute_reply.started":"2023-10-19T19:07:16.234657Z","shell.execute_reply":"2023-10-19T19:07:16.256035Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           0     1      2       3       4     5       6  7      8\nBERT   [CLS]   Tim    Spa  ##rrow   lives   San   Diego  !  [SEP]\nXLM-R    <s>  ▁Tim  ▁Spar     row  ▁lives  ▁San  ▁Diego  !   </s>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BERT</th>\n      <td>[CLS]</td>\n      <td>Tim</td>\n      <td>Spa</td>\n      <td>##rrow</td>\n      <td>lives</td>\n      <td>San</td>\n      <td>Diego</td>\n      <td>!</td>\n      <td>[SEP]</td>\n    </tr>\n    <tr>\n      <th>XLM-R</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import XLMRobertaForTokenClassification\nimport torch\n\nxlmr_model_name = \"xlm-roberta-base\"\nindex2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}\nnum_labels = tags.num_classes\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nxlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n    xlmr_model_name,\n    num_labels = num_labels,\n    id2label=index2tag,\n    label2id=tag2index\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:16.258394Z","iopub.execute_input":"2023-10-19T19:07:16.259406Z","iopub.status.idle":"2023-10-19T19:07:34.923436Z","shell.execute_reply.started":"2023-10-19T19:07:16.259374Z","shell.execute_reply":"2023-10-19T19:07:34.922300Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b22421efca45e3a8894adb8d63dd77"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ids = xlmr_tokenizer.encode(text, return_tensors = \"pt\")\n\npd.DataFrame([xlmr_tokens, input_ids[0].numpy()],  index = [\"Tokens\", \"Input IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:34.924868Z","iopub.execute_input":"2023-10-19T19:07:34.925961Z","iopub.status.idle":"2023-10-19T19:07:34.940352Z","shell.execute_reply.started":"2023-10-19T19:07:34.925930Z","shell.execute_reply":"2023-10-19T19:07:34.939347Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             0      1      2      3       4     5       6   7     8\nTokens     <s>   ▁Tim  ▁Spar    row  ▁lives  ▁San  ▁Diego   !  </s>\nInput IDs    0  13320  37456  15555   60742  1735   59826  38     2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>13320</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>60742</td>\n      <td>1735</td>\n      <td>59826</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"outputs = xlmr_model(input_ids.to(device)).logits\n\npredictions = torch.argmax(outputs, dim=-1)\n\npreds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n\npd.DataFrame( [xlmr_tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:34.942502Z","iopub.execute_input":"2023-10-19T19:07:34.943106Z","iopub.status.idle":"2023-10-19T19:07:35.132518Z","shell.execute_reply.started":"2023-10-19T19:07:34.943069Z","shell.execute_reply":"2023-10-19T19:07:35.131568Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"          0      1      2      3       4      5       6      7     8\nTokens  <s>   ▁Tim  ▁Spar    row  ▁lives   ▁San  ▁Diego      !  </s>\nTags      O  B-ORG  B-ORG  B-ORG       O  B-ORG   B-ORG  B-ORG     O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>B-ORG</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>B-ORG</td>\n      <td>B-ORG</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tag_text(text, tags, model, tokenizer):\n    tokens = tokenizer(text).tokens()\n    input_ids = xlmr_tokenizer.encode(\n        text, return_tensors = \"pt\").to(device)\n    outputs = model(input_ids)[0]\n    predictions = torch.argmax(outputs, dim=2)\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.133686Z","iopub.execute_input":"2023-10-19T19:07:35.133957Z","iopub.status.idle":"2023-10-19T19:07:35.139521Z","shell.execute_reply.started":"2023-10-19T19:07:35.133933Z","shell.execute_reply":"2023-10-19T19:07:35.138614Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Tokenizer for NER Analysis </div></b>","metadata":{}},{"cell_type":"code","source":"words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n\npd.DataFrame([words, labels], index = [\"words\", \"labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.140869Z","iopub.execute_input":"2023-10-19T19:07:35.141153Z","iopub.status.idle":"2023-10-19T19:07:35.169289Z","shell.execute_reply.started":"2023-10-19T19:07:35.141129Z","shell.execute_reply":"2023-10-19T19:07:35.168155Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nwords   2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nlabels      0           0   0    0         5      6   0    0           5   \n\n                  9        10 11  \nwords   Woiwodschaft  Pommern  .  \nlabels             5        6  0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>words</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(de_example[\"tokens\"],is_split_into_words=True)\n\ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n\npd.DataFrame([tokens], index=[\"Tokens\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.170568Z","iopub.execute_input":"2023-10-19T19:07:35.170869Z","iopub.status.idle":"2023-10-19T19:07:35.193594Z","shell.execute_reply.started":"2023-10-19T19:07:35.170845Z","shell.execute_reply":"2023-10-19T19:07:35.192713Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         0       1           2  3    4     5     6   7    8      9   ...   15  \\\nTokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n\n       16   17      18   19    20 21 22 23    24  \nTokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n\n[1 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = tokenized_input.word_ids()\n\npd.DataFrame([tokens, word_ids], index = [\"Tokens\",\"Word IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.194758Z","iopub.execute_input":"2023-10-19T19:07:35.195028Z","iopub.status.idle":"2023-10-19T19:07:35.214830Z","shell.execute_reply.started":"2023-10-19T19:07:35.195005Z","shell.execute_reply":"2023-10-19T19:07:35.213607Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            0       1           2  3    4     5     6   7    8      9   ...  \\\nTokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \nWord IDs  None       0           1  1    2     3     4   4    4      5  ...   \n\n           15 16   17      18   19    20  21  22  23    24  \nTokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \nWord IDs    9  9    9       9   10    10  10  11  11  None  \n\n[2 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"previous_word_idx = None\nlabel_ids = []\nfor word_idx in word_ids:\n    if word_idx is None or word_idx == previous_word_idx:\n        label_ids.append(-100)\n    elif word_idx != previous_word_idx:\n        label_ids.append(labels[word_idx])\n    previous_word_idx = word_idx\n\nlabels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n\nindex = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\npd.DataFrame([tokens, word_ids, label_ids, labels], index = index)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.216477Z","iopub.execute_input":"2023-10-19T19:07:35.216910Z","iopub.status.idle":"2023-10-19T19:07:35.241121Z","shell.execute_reply.started":"2023-10-19T19:07:35.216872Z","shell.execute_reply":"2023-10-19T19:07:35.240019Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"             0       1           2     3    4     5      6     7     8   \\\nTokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \nWord IDs   None       0           1     1    2     3      4     4     4   \nLabel IDs  -100       0           0  -100    0     0      5  -100  -100   \nLabels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n\n              9   ...     15    16    17      18     19    20    21  22    23  \\\nTokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \nWord IDs       5  ...      9     9     9       9     10    10    10  11    11   \nLabel IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \nLabels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n\n             24  \nTokens     </s>  \nWord IDs   None  \nLabel IDs  -100  \nLabels      IGN  \n\n[4 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>Label IDs</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>...</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], \n                                     truncation = True,\n                                     is_split_into_words = True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs        ","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.242234Z","iopub.execute_input":"2023-10-19T19:07:35.242636Z","iopub.status.idle":"2023-10-19T19:07:35.255299Z","shell.execute_reply.started":"2023-10-19T19:07:35.242590Z","shell.execute_reply":"2023-10-19T19:07:35.254302Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels,\n                     batched=True,\n                     remove_columns=[\"langs\", \"ner_tags\", \"tokens\"])\n\npanx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:35.256611Z","iopub.execute_input":"2023-10-19T19:07:35.257631Z","iopub.status.idle":"2023-10-19T19:07:38.024110Z","shell.execute_reply.started":"2023-10-19T19:07:35.257591Z","shell.execute_reply":"2023-10-19T19:07:38.023183Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75e9dd3fd83c438f8049e23bf98aa3fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c4eba46aa94e1f8390786a16b8f7b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99e7577f7b734b8cb1036f0e1eebf5a6"}},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Model Metrics </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q seqeval","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:38.025424Z","iopub.execute_input":"2023-10-19T19:07:38.026444Z","iopub.status.idle":"2023-10-19T19:07:55.481814Z","shell.execute_reply.started":"2023-10-19T19:07:38.026415Z","shell.execute_reply":"2023-10-19T19:07:55.480466Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\ny_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\ny_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\n\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:55.483512Z","iopub.execute_input":"2023-10-19T19:07:55.484080Z","iopub.status.idle":"2023-10-19T19:07:55.827150Z","shell.execute_reply.started":"2023-10-19T19:07:55.484035Z","shell.execute_reply":"2023-10-19T19:07:55.826011Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        MISC       0.00      0.00      0.00         1\n         PER       1.00      1.00      1.00         1\n\n   micro avg       0.50      0.50      0.50         2\n   macro avg       0.50      0.50      0.50         2\nweighted avg       0.50      0.50      0.50         2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef align_prediction(predictions, label_ids):\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_len):\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(index2tag[label_ids[bathc_idx][seq_idx]])\n                example_preds.append(index2tag[preds[bathc_idx][seq_idx]])\n        \n        labels_list.append(example_labels)  \n        preds_list.append(example_preds) \n    \n    return preds_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2023-10-19T19:07:55.829117Z","iopub.execute_input":"2023-10-19T19:07:55.829704Z","iopub.status.idle":"2023-10-19T19:07:55.837663Z","shell.execute_reply.started":"2023-10-19T19:07:55.829652Z","shell.execute_reply":"2023-10-19T19:07:55.836242Z"},"trusted":true},"execution_count":23,"outputs":[]}]}