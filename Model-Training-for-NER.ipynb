{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Loading the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:19:15.150186Z","iopub.execute_input":"2023-10-21T10:19:15.150486Z","iopub.status.idle":"2023-10-21T10:19:28.525619Z","shell.execute_reply.started":"2023-10-21T10:19:15.150458Z","shell.execute_reply":"2023-10-21T10:19:28.524542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom collections import defaultdict\nfrom datasets import DatasetDict\n\n\nlangs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs= [0.629, 0.229, 0.084, 0.059]\n\npanx_ch = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    for split in ds:\n        panx_ch[lang][split] = (\n            ds[split].shuffle(seed=0).select(range(int(frac*ds[split].num_rows))))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:19:28.527868Z","iopub.execute_input":"2023-10-21T10:19:28.528225Z","iopub.status.idle":"2023-10-21T10:20:12.827342Z","shell.execute_reply.started":"2023-10-21T10:19:28.528193Z","shell.execute_reply":"2023-10-21T10:20:12.826267Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fa5b0ef9fc4888b3a962ea9e09d486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a9c24649254aeaaa47ca008d88201f"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62fdae20f02c41909440463200fdef27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5d0fd39c19412db30f3d0258048045"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf17444cbe946e3b3c83e4b74689122"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552ecd48ebb84062967f8f112128606b"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7154d3b91b94275af710379187c8b86"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's take a look at the number of training examples of all datasets:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"number of training examples\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:12.828838Z","iopub.execute_input":"2023-10-21T10:20:12.829966Z","iopub.status.idle":"2023-10-21T10:20:12.859769Z","shell.execute_reply.started":"2023-10-21T10:20:12.829926Z","shell.execute_reply":"2023-10-21T10:20:12.858493Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                de    fr    it    en\nnumber of training examples  12580  4580  1680  1180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>number of training examples</th>\n      <td>12580</td>\n      <td>4580</td>\n      <td>1680</td>\n      <td>1180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Understanding the Dataset </div></b>","metadata":{}},{"cell_type":"code","source":"element = panx_ch[\"de\"][\"train\"][0]\n\nfor key, value in element.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:12.864062Z","iopub.execute_input":"2023-10-21T10:20:12.864500Z","iopub.status.idle":"2023-10-21T10:20:12.871878Z","shell.execute_reply.started":"2023-10-21T10:20:12.864462Z","shell.execute_reply":"2023-10-21T10:20:12.870891Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\nner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\nlangs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n","output_type":"stream"}]},{"cell_type":"code","source":"for key, value in panx_ch[\"de\"][\"train\"].features.items():\n    print(f\"{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:12.873184Z","iopub.execute_input":"2023-10-21T10:20:12.873479Z","iopub.status.idle":"2023-10-21T10:20:12.882656Z","shell.execute_reply.started":"2023-10-21T10:20:12.873454Z","shell.execute_reply":"2023-10-21T10:20:12.881618Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\nner_tags: Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\nlangs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:12.883894Z","iopub.execute_input":"2023-10-21T10:20:12.884293Z","iopub.status.idle":"2023-10-21T10:20:12.894569Z","shell.execute_reply.started":"2023-10-21T10:20:12.884265Z","shell.execute_reply":"2023-10-21T10:20:12.893715Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Data Preprocessing </div></b>","metadata":{}},{"cell_type":"code","source":"def create_tag_names(batch):\n    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n\npanx_de = panx_ch[\"de\"].map(create_tag_names)\nde_example = panx_de[\"train\"][0]\npd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:12.895664Z","iopub.execute_input":"2023-10-21T10:20:12.896061Z","iopub.status.idle":"2023-10-21T10:20:17.282842Z","shell.execute_reply.started":"2023-10-21T10:20:12.896005Z","shell.execute_reply":"2023-10-21T10:20:17.281934Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12580 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f399973d8dc3466ba908086aee94b6ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b8890e854341aeb6a5304d096ae051"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c0d5831fee43fa90d45dc59e44e248"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nTokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nTags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n\n                  9        10 11  \nTokens  Woiwodschaft  Pommern  .  \nTags           B-LOC    I-LOC  O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\nsplit2freqs = defaultdict(Counter)\n\nfor split, dataset in panx_de.items():\n    for row in dataset[\"ner_tags_str\"]:\n        for tag in row:\n            if tag.startswith(\"B\"):\n                tag_type = tag.split(\"-\")[1]\n                split2freqs[split][tag_type] +=1\n\npd.DataFrame.from_dict(split2freqs, orient = \"index\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:17.284097Z","iopub.execute_input":"2023-10-21T10:20:17.284476Z","iopub.status.idle":"2023-10-21T10:20:17.784635Z","shell.execute_reply.started":"2023-10-21T10:20:17.284440Z","shell.execute_reply":"2023-10-21T10:20:17.783657Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Bert Tokenizer vs XLM-R Tokenizer </div></b>","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\nxlmr_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:17.785783Z","iopub.execute_input":"2023-10-21T10:20:17.786061Z","iopub.status.idle":"2023-10-21T10:20:24.109906Z","shell.execute_reply.started":"2023-10-21T10:20:17.786014Z","shell.execute_reply":"2023-10-21T10:20:24.108835Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9828c9815241b090c6cfc9135ea4a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b1573f54c24382a5d07d28f618a980"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e80cdb926f248299792314cb0106cea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2a7bdb09d14bed8a24dc23af8cfa92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e808ebaeb448baacc4f05ab3402408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58fe4817868f4a4d99c35b995907634f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b56eb64183da4004b8dfc6360ea89d14"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"Tim Sparrow lives San Diego!\"\n\nbert_tokens = bert_tokenizer(text).tokens()\nxlmr_tokens = xlmr_tokenizer(text).tokens()\n\npd.DataFrame([bert_tokens, xlmr_tokens], index = [\"BERT\",\"XLM-R\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:24.113345Z","iopub.execute_input":"2023-10-21T10:20:24.113794Z","iopub.status.idle":"2023-10-21T10:20:24.133885Z","shell.execute_reply.started":"2023-10-21T10:20:24.113768Z","shell.execute_reply":"2023-10-21T10:20:24.133065Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           0     1      2       3       4     5       6  7      8\nBERT   [CLS]   Tim    Spa  ##rrow   lives   San   Diego  !  [SEP]\nXLM-R    <s>  ▁Tim  ▁Spar     row  ▁lives  ▁San  ▁Diego  !   </s>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BERT</th>\n      <td>[CLS]</td>\n      <td>Tim</td>\n      <td>Spa</td>\n      <td>##rrow</td>\n      <td>lives</td>\n      <td>San</td>\n      <td>Diego</td>\n      <td>!</td>\n      <td>[SEP]</td>\n    </tr>\n    <tr>\n      <th>XLM-R</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import XLMRobertaForTokenClassification\nimport torch\n\nxlmr_model_name = \"xlm-roberta-base\"\nindex2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}\nnum_labels = tags.num_classes\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nxlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n    xlmr_model_name,\n    num_labels = num_labels,\n    id2label=index2tag,\n    label2id=tag2index\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:24.134891Z","iopub.execute_input":"2023-10-21T10:20:24.135157Z","iopub.status.idle":"2023-10-21T10:20:50.235102Z","shell.execute_reply.started":"2023-10-21T10:20:24.135133Z","shell.execute_reply":"2023-10-21T10:20:50.233974Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5173800ad6c0451e97ec2273adfb1fc1"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ids = xlmr_tokenizer.encode(text, return_tensors = \"pt\")\n\npd.DataFrame([xlmr_tokens, input_ids[0].numpy()],  index = [\"Tokens\", \"Input IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:50.236907Z","iopub.execute_input":"2023-10-21T10:20:50.237411Z","iopub.status.idle":"2023-10-21T10:20:50.256111Z","shell.execute_reply.started":"2023-10-21T10:20:50.237373Z","shell.execute_reply":"2023-10-21T10:20:50.254829Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             0      1      2      3       4     5       6   7     8\nTokens     <s>   ▁Tim  ▁Spar    row  ▁lives  ▁San  ▁Diego   !  </s>\nInput IDs    0  13320  37456  15555   60742  1735   59826  38     2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>13320</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>60742</td>\n      <td>1735</td>\n      <td>59826</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"outputs = xlmr_model(input_ids.to(device)).logits\n\npredictions = torch.argmax(outputs, dim=-1)\n\npreds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n\npd.DataFrame( [xlmr_tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:50.257349Z","iopub.execute_input":"2023-10-21T10:20:50.257645Z","iopub.status.idle":"2023-10-21T10:20:53.353802Z","shell.execute_reply.started":"2023-10-21T10:20:50.257620Z","shell.execute_reply":"2023-10-21T10:20:53.352540Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"            0      1      2      3       4      5       6      7      8\nTokens    <s>   ▁Tim  ▁Spar    row  ▁lives   ▁San  ▁Diego      !   </s>\nTags    I-ORG  I-ORG  I-ORG  I-ORG   I-ORG  I-ORG   I-ORG  I-ORG  I-ORG","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁lives</td>\n      <td>▁San</td>\n      <td>▁Diego</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tag_text(text, tags, model, tokenizer):\n    tokens = tokenizer(text).tokens()\n    input_ids = xlmr_tokenizer.encode(\n        text, return_tensors = \"pt\").to(device)\n    outputs = model(input_ids)[0]\n    predictions = torch.argmax(outputs, dim=2)\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index = [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:53.357633Z","iopub.execute_input":"2023-10-21T10:20:53.358272Z","iopub.status.idle":"2023-10-21T10:20:53.367461Z","shell.execute_reply.started":"2023-10-21T10:20:53.358235Z","shell.execute_reply":"2023-10-21T10:20:53.365641Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Tokenizer for NER Analysis </div></b>","metadata":{}},{"cell_type":"code","source":"words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n\npd.DataFrame([words, labels], index = [\"words\", \"labels\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:53.368790Z","iopub.execute_input":"2023-10-21T10:20:53.369156Z","iopub.status.idle":"2023-10-21T10:20:57.330957Z","shell.execute_reply.started":"2023-10-21T10:20:53.369124Z","shell.execute_reply":"2023-10-21T10:20:57.329938Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nwords   2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nlabels      0           0   0    0         5      6   0    0           5   \n\n                  9        10 11  \nwords   Woiwodschaft  Pommern  .  \nlabels             5        6  0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>words</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(de_example[\"tokens\"],is_split_into_words=True)\n\ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n\npd.DataFrame([tokens], index=[\"Tokens\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:57.332304Z","iopub.execute_input":"2023-10-21T10:20:57.332655Z","iopub.status.idle":"2023-10-21T10:20:57.358218Z","shell.execute_reply.started":"2023-10-21T10:20:57.332619Z","shell.execute_reply":"2023-10-21T10:20:57.357250Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         0       1           2  3    4     5     6   7    8      9   ...   15  \\\nTokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n\n       16   17      18   19    20 21 22 23    24  \nTokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n\n[1 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = tokenized_input.word_ids()\n\npd.DataFrame([tokens, word_ids], index = [\"Tokens\",\"Word IDs\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:57.359236Z","iopub.execute_input":"2023-10-21T10:20:57.359561Z","iopub.status.idle":"2023-10-21T10:20:57.379553Z","shell.execute_reply.started":"2023-10-21T10:20:57.359528Z","shell.execute_reply":"2023-10-21T10:20:57.378592Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            0       1           2  3    4     5     6   7    8      9   ...  \\\nTokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \nWord IDs  None       0           1  1    2     3     4   4    4      5  ...   \n\n           15 16   17      18   19    20  21  22  23    24  \nTokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \nWord IDs    9  9    9       9   10    10  10  11  11  None  \n\n[2 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"previous_word_idx = None\nlabel_ids = []\nfor word_idx in word_ids:\n    if word_idx is None or word_idx == previous_word_idx:\n        label_ids.append(-100)\n    elif word_idx != previous_word_idx:\n        label_ids.append(labels[word_idx])\n    previous_word_idx = word_idx\n\nlabels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n\nindex = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\npd.DataFrame([tokens, word_ids, label_ids, labels], index = index)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:57.380878Z","iopub.execute_input":"2023-10-21T10:20:57.381258Z","iopub.status.idle":"2023-10-21T10:20:57.407353Z","shell.execute_reply.started":"2023-10-21T10:20:57.381224Z","shell.execute_reply":"2023-10-21T10:20:57.406470Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"             0       1           2     3    4     5      6     7     8   \\\nTokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \nWord IDs   None       0           1     1    2     3      4     4     4   \nLabel IDs  -100       0           0  -100    0     0      5  -100  -100   \nLabels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n\n              9   ...     15    16    17      18     19    20    21  22    23  \\\nTokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \nWord IDs       5  ...      9     9     9       9     10    10    10  11    11   \nLabel IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \nLabels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n\n             24  \nTokens     </s>  \nWord IDs   None  \nLabel IDs  -100  \nLabels      IGN  \n\n[4 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>Label IDs</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>...</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], \n                                     truncation = True,\n                                     is_split_into_words = True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs        ","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:57.408545Z","iopub.execute_input":"2023-10-21T10:20:57.408872Z","iopub.status.idle":"2023-10-21T10:20:57.422405Z","shell.execute_reply.started":"2023-10-21T10:20:57.408841Z","shell.execute_reply":"2023-10-21T10:20:57.421570Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels,\n                     batched=True,\n                     remove_columns=[\"langs\", \"ner_tags\", \"tokens\"])\n\npanx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:20:57.423478Z","iopub.execute_input":"2023-10-21T10:20:57.423806Z","iopub.status.idle":"2023-10-21T10:21:00.708553Z","shell.execute_reply.started":"2023-10-21T10:20:57.423775Z","shell.execute_reply":"2023-10-21T10:21:00.707703Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f6598a240b4a27a2a56a11e3843646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf72133c42e4d5ca02b8974fa2dbac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c296dd17ac649dd9ca2055992b6a0f8"}},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Model Metrics </div></b>","metadata":{}},{"cell_type":"code","source":"!pip install -q seqeval","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:21:00.709801Z","iopub.execute_input":"2023-10-21T10:21:00.710685Z","iopub.status.idle":"2023-10-21T10:21:16.797066Z","shell.execute_reply.started":"2023-10-21T10:21:00.710646Z","shell.execute_reply":"2023-10-21T10:21:16.796048Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report\n\ny_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\ny_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n          [\"B-PER\", \"I-PER\", \"O\"]]\n\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:21:16.798543Z","iopub.execute_input":"2023-10-21T10:21:16.798859Z","iopub.status.idle":"2023-10-21T10:21:17.065278Z","shell.execute_reply.started":"2023-10-21T10:21:16.798831Z","shell.execute_reply":"2023-10-21T10:21:17.064163Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        MISC       0.00      0.00      0.00         1\n         PER       1.00      1.00      1.00         1\n\n   micro avg       0.50      0.50      0.50         2\n   macro avg       0.50      0.50      0.50         2\nweighted avg       0.50      0.50      0.50         2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef align_predictions(predictions, label_ids):\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_len):\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n        \n        labels_list.append(example_labels)  \n        preds_list.append(example_preds) \n    \n    return preds_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:26:59.755184Z","iopub.execute_input":"2023-10-21T10:26:59.755559Z","iopub.status.idle":"2023-10-21T10:26:59.762945Z","shell.execute_reply.started":"2023-10-21T10:26:59.755531Z","shell.execute_reply":"2023-10-21T10:26:59.761927Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Model Training </div></b>","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nnum_epochs = 2\nbatch_size = 24\nlogging_steps = len(panx_de_encoded[\"train\"]) // batch_size\nmodel_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n\ntraining_args = TrainingArguments(\n    output_dir=model_name, \n    log_level=\"error\", \n    num_train_epochs=num_epochs, \n    per_device_train_batch_size=batch_size, \n    per_device_eval_batch_size=batch_size, \n    evaluation_strategy=\"epoch\", \n    save_steps=1e6, \n    weight_decay=0.01, \n    logging_steps=logging_steps, \n    report_to = \"none\",\n    push_to_hub=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:27:02.989896Z","iopub.execute_input":"2023-10-21T10:27:02.990843Z","iopub.status.idle":"2023-10-21T10:27:02.998341Z","shell.execute_reply.started":"2023-10-21T10:27:02.990804Z","shell.execute_reply":"2023-10-21T10:27:02.997014Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:22:14.023225Z","iopub.execute_input":"2023-10-21T10:22:14.023609Z","iopub.status.idle":"2023-10-21T10:22:14.052651Z","shell.execute_reply.started":"2023-10-21T10:22:14.023580Z","shell.execute_reply":"2023-10-21T10:22:14.051787Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c77e23457c42f8b02f52bf9634117c"}},"metadata":{}}]},{"cell_type":"code","source":"from seqeval.metrics import f1_score\n\ndef compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(eval_pred.predictions, \n                                       eval_pred.label_ids)\n    return {\"f1\": f1_score(y_true, y_pred)}","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:27:05.758957Z","iopub.execute_input":"2023-10-21T10:27:05.759441Z","iopub.status.idle":"2023-10-21T10:27:05.765152Z","shell.execute_reply.started":"2023-10-21T10:27:05.759410Z","shell.execute_reply":"2023-10-21T10:27:05.763978Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:27:10.507894Z","iopub.execute_input":"2023-10-21T10:27:10.508810Z","iopub.status.idle":"2023-10-21T10:27:10.513306Z","shell.execute_reply.started":"2023-10-21T10:27:10.508776Z","shell.execute_reply":"2023-10-21T10:27:10.512148Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return xlmr_model","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:22:36.738482Z","iopub.execute_input":"2023-10-21T10:22:36.738861Z","iopub.status.idle":"2023-10-21T10:22:36.743154Z","shell.execute_reply.started":"2023-10-21T10:22:36.738832Z","shell.execute_reply":"2023-10-21T10:22:36.742294Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model_init=model_init, \n    args=training_args,\n    data_collator=data_collator, \n    compute_metrics=compute_metrics,\n    train_dataset=panx_de_encoded[\"train\"],\n    eval_dataset=panx_de_encoded[\"validation\"], \n    tokenizer=xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:27:14.857935Z","iopub.execute_input":"2023-10-21T10:27:14.858620Z","iopub.status.idle":"2023-10-21T10:27:15.018391Z","shell.execute_reply.started":"2023-10-21T10:27:14.858587Z","shell.execute_reply":"2023-10-21T10:27:15.017465Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.push_to_hub(commit_message=\"Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:27:17.959860Z","iopub.execute_input":"2023-10-21T10:27:17.960591Z","iopub.status.idle":"2023-10-21T10:33:48.825374Z","shell.execute_reply.started":"2023-10-21T10:27:17.960557Z","shell.execute_reply":"2023-10-21T10:33:48.824434Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='526' max='526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [526/526 05:28, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.106300</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db59468c98f4ddfa3265d4d2a7958e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d552a7044242a28105d56287890448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11f83e69a3b40d589cbd4d73a270972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a915df4487844156a33cd2499c148fed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564d883140254fbfa46fcba5b9e012f6"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Tirendaz/xlm-roberta-base-finetuned-panx-de/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:34:34.117328Z","iopub.execute_input":"2023-10-21T10:34:34.117942Z","iopub.status.idle":"2023-10-21T10:34:34.140819Z","shell.execute_reply.started":"2023-10-21T10:34:34.117913Z","shell.execute_reply":"2023-10-21T10:34:34.139910Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   epoch    loss  eval_loss   eval_f1\n0   1.00     NaN   0.164799  0.832489\n1   1.99  0.1063        NaN       NaN\n2   2.00     NaN   0.138655  0.858539\n3   2.00     NaN        NaN       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>loss</th>\n      <th>eval_loss</th>\n      <th>eval_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.99</td>\n      <td>0.1063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.00</td>\n      <td>NaN</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:34:47.394885Z","iopub.execute_input":"2023-10-21T10:34:47.395634Z","iopub.status.idle":"2023-10-21T10:34:47.409268Z","shell.execute_reply.started":"2023-10-21T10:34:47.395600Z","shell.execute_reply":"2023-10-21T10:34:47.408089Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   Epoch  Training Loss  Validation Loss        F1\n0   1.00            NaN         0.164799  0.832489\n1   1.99         0.1063              NaN       NaN\n2   2.00            NaN         0.138655  0.858539\n3   2.00            NaN              NaN       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>NaN</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.99</td>\n      <td>0.1063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.00</td>\n      <td>NaN</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:35:00.877169Z","iopub.execute_input":"2023-10-21T10:35:00.877530Z","iopub.status.idle":"2023-10-21T10:35:00.890059Z","shell.execute_reply.started":"2023-10-21T10:35:00.877502Z","shell.execute_reply":"2023-10-21T10:35:00.889102Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   Epoch  Training Loss  Validation Loss        F1\n0      1            NaN         0.164799  0.832489\n1      2         0.1063              NaN       NaN\n2      2            NaN         0.138655  0.858539\n3      2            NaN              NaN       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Training Loss'] = df[\"Training Loss\"].ffill()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:35:29.706795Z","iopub.execute_input":"2023-10-21T10:35:29.707430Z","iopub.status.idle":"2023-10-21T10:35:29.724198Z","shell.execute_reply.started":"2023-10-21T10:35:29.707382Z","shell.execute_reply":"2023-10-21T10:35:29.723072Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"   Epoch  Training Loss  Validation Loss        F1\n0      1            NaN         0.164799  0.832489\n1      2         0.1063              NaN       NaN\n2      2         0.1063         0.138655  0.858539\n3      2         0.1063              NaN       NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\ndf.drop_duplicates()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:35:36.843692Z","iopub.execute_input":"2023-10-21T10:35:36.844517Z","iopub.status.idle":"2023-10-21T10:35:36.865042Z","shell.execute_reply.started":"2023-10-21T10:35:36.844483Z","shell.execute_reply":"2023-10-21T10:35:36.864084Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   Epoch  Training Loss  Validation Loss        F1\n0      1            NaN         0.164799  0.832489\n1      2         0.1063         0.138655  0.858539\n2      2         0.1063         0.138655  0.858539\n3      2         0.1063         0.138655  0.858539","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.164799</td>\n      <td>0.832489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>0.1063</td>\n      <td>0.138655</td>\n      <td>0.858539</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"text_de = \"Tim Dean  ist ein Informatiker bei Google in Kalifornien\"\ntag_text(text_de, tags, trainer.model, xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T10:38:54.899011Z","iopub.execute_input":"2023-10-21T10:38:54.899384Z","iopub.status.idle":"2023-10-21T10:38:54.933917Z","shell.execute_reply.started":"2023-10-21T10:38:54.899358Z","shell.execute_reply":"2023-10-21T10:38:54.932962Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"         0      1      2      3     4     5           6    7     8        9   \\\nTokens  <s>   ▁Tim    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \nTags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n\n         10          11     12    13  \nTokens  ▁in  ▁Kaliforni     en  </s>  \nTags      O       B-LOC  I-LOC     O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Tim</td>\n      <td>▁De</td>\n      <td>an</td>\n      <td>▁ist</td>\n      <td>▁ein</td>\n      <td>▁Informati</td>\n      <td>ker</td>\n      <td>▁bei</td>\n      <td>▁Google</td>\n      <td>▁in</td>\n      <td>▁Kaliforni</td>\n      <td>en</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}