{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-Tuning Mistral","metadata":{}},{"cell_type":"code","source":"!pip install -q -U transformers bitsandbytes peft datasets accelerate trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T08:11:29.751726Z","iopub.execute_input":"2023-12-01T08:11:29.752024Z","iopub.status.idle":"2023-12-01T08:12:01.743112Z","shell.execute_reply.started":"2023-12-01T08:11:29.751981Z","shell.execute_reply":"2023-12-01T08:12:01.741813Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nbase_model = \"mistralai/Mistral-7B-v0.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    base_model, \n    padding_side = \"right\",\n    add_eos_token = True,\n)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:12:01.745395Z","iopub.execute_input":"2023-12-01T08:12:01.745717Z","iopub.status.idle":"2023-12-01T08:12:08.282643Z","shell.execute_reply.started":"2023-12-01T08:12:01.745684Z","shell.execute_reply":"2023-12-01T08:12:08.281500Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/966 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea3efbae17444ed8ac04845439310b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f790b08773e4a1fa2b6b75b867b8870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e970425ec75472d9f8a77676b2b6695"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0257f7b621744bb4b870b7257baa0b81"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:12:08.284135Z","iopub.execute_input":"2023-12-01T08:12:08.284990Z","iopub.status.idle":"2023-12-01T08:12:08.292272Z","shell.execute_reply.started":"2023-12-01T08:12:08.284937Z","shell.execute_reply":"2023-12-01T08:12:08.291268Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading the Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:12:08.295760Z","iopub.execute_input":"2023-12-01T08:12:08.296434Z","iopub.status.idle":"2023-12-01T08:12:08.309844Z","shell.execute_reply.started":"2023-12-01T08:12:08.296395Z","shell.execute_reply":"2023-12-01T08:12:08.309004Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    load_in_4bit=True,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:12:08.310994Z","iopub.execute_input":"2023-12-01T08:12:08.311564Z","iopub.status.idle":"2023-12-01T08:14:25.445988Z","shell.execute_reply.started":"2023-12-01T08:12:08.311538Z","shell.execute_reply":"2023-12-01T08:14:25.444856Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0edbfc109594183988c04583369de74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592b0298f2514c58871d659680b24aa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b09d204f37740d6a9765fb66c37f81f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4309a999cd4f81b3de05141259fdac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1bdbea58344f6e81127aaeef3d14ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45c7c77095244cc8cb82c6b424bf76a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6dea523a3d4640a33ba1a4c08a8b1a"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = \"databricks/databricks-dolly-15k\"\n\ntrain_dataset = load_dataset(dataset_name, split=\"train[0:800]\")\neval_dataset = load_dataset(dataset_name, split=\"train[800:1000]\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:25.447658Z","iopub.execute_input":"2023-12-01T08:14:25.448609Z","iopub.status.idle":"2023-12-01T08:14:29.397279Z","shell.execute_reply.started":"2023-12-01T08:14:25.448569Z","shell.execute_reply":"2023-12-01T08:14:29.396497Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bf63803f124ff0b74b46715ea356b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deef6fcb668444628d55ccb51085a482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/13.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6377ecf3628e438181b91a63246d826f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51dc579ab59435c800c726f239ef3cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a199ce3f5e0d45cb84c403e4f63c4a5d"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Understanding the Model","metadata":{}},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.398526Z","iopub.execute_input":"2023-12-01T08:14:29.399028Z","iopub.status.idle":"2023-12-01T08:14:29.405317Z","shell.execute_reply.started":"2023-12-01T08:14:29.398998Z","shell.execute_reply":"2023-12-01T08:14:29.404155Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'context', 'response', 'category'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.406523Z","iopub.execute_input":"2023-12-01T08:14:29.406797Z","iopub.status.idle":"2023-12-01T08:14:29.484381Z","shell.execute_reply.started":"2023-12-01T08:14:29.406774Z","shell.execute_reply":"2023-12-01T08:14:29.483409Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           instruction  \\\n0           When did Virgin Australia start operating?   \n1             Which is a species of fish? Tope or Rope   \n2       Why can camels survive for long without water?   \n3    Alice's parents have three daughters: Amy, Jes...   \n4                      When was Tomoaki Komorida born?   \n..                                                 ...   \n795         Who is the founder of the Communist Party?   \n796                                 What is gardening?   \n797  What are your thoughts of Michael Jackson as a...   \n798                     What is the largest pollutant?   \n799                        Why do people drink coffee?   \n\n                                               context  \\\n0    Virgin Australia, the trading name of Virgin A...   \n1                                                        \n2                                                        \n3                                                        \n4    Komorida was born in Kumamoto Prefecture on Ju...   \n..                                                 ...   \n795                                                      \n796  Gardening is the practice of growing and culti...   \n797                                                      \n798                                                      \n799                                                      \n\n                                              response                category  \n0    Virgin Australia commenced services on 31 Augu...               closed_qa  \n1                                                 Tope          classification  \n2    Camels use the fat in their humps to keep them...                 open_qa  \n3              The name of the third daughter is Alice                 open_qa  \n4           Tomoaki Komorida was born on July 10,1981.               closed_qa  \n..                                                 ...                     ...  \n795                                              Lenin                 open_qa  \n796  Gardening is laying out and caring for a plot ...  information_extraction  \n797  Michael Jackson is acclaimed as the greatest p...        creative_writing  \n798  Carbon dioxide (CO2) - a greenhouse gas emitte...              general_qa  \n799  Coffee contains caffeine which is a stimulant....              general_qa  \n\n[800 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>context</th>\n      <th>response</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When did Virgin Australia start operating?</td>\n      <td>Virgin Australia, the trading name of Virgin A...</td>\n      <td>Virgin Australia commenced services on 31 Augu...</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which is a species of fish? Tope or Rope</td>\n      <td></td>\n      <td>Tope</td>\n      <td>classification</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why can camels survive for long without water?</td>\n      <td></td>\n      <td>Camels use the fat in their humps to keep them...</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alice's parents have three daughters: Amy, Jes...</td>\n      <td></td>\n      <td>The name of the third daughter is Alice</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When was Tomoaki Komorida born?</td>\n      <td>Komorida was born in Kumamoto Prefecture on Ju...</td>\n      <td>Tomoaki Komorida was born on July 10,1981.</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>Who is the founder of the Communist Party?</td>\n      <td></td>\n      <td>Lenin</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>What is gardening?</td>\n      <td>Gardening is the practice of growing and culti...</td>\n      <td>Gardening is laying out and caring for a plot ...</td>\n      <td>information_extraction</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>What are your thoughts of Michael Jackson as a...</td>\n      <td></td>\n      <td>Michael Jackson is acclaimed as the greatest p...</td>\n      <td>creative_writing</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>What is the largest pollutant?</td>\n      <td></td>\n      <td>Carbon dioxide (CO2) - a greenhouse gas emitte...</td>\n      <td>general_qa</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Why do people drink coffee?</td>\n      <td></td>\n      <td>Coffee contains caffeine which is a stimulant....</td>\n      <td>general_qa</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().dtypes","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.485663Z","iopub.execute_input":"2023-12-01T08:14:29.486015Z","iopub.status.idle":"2023-12-01T08:14:29.497190Z","shell.execute_reply.started":"2023-12-01T08:14:29.485983Z","shell.execute_reply":"2023-12-01T08:14:29.496187Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"instruction    object\ncontext        object\nresponse       object\ncategory       object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().value_counts(\"category\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.500947Z","iopub.execute_input":"2023-12-01T08:14:29.501254Z","iopub.status.idle":"2023-12-01T08:14:29.513953Z","shell.execute_reply.started":"2023-12-01T08:14:29.501230Z","shell.execute_reply":"2023-12-01T08:14:29.513021Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"category\nopen_qa                   202\ngeneral_qa                132\nclassification            111\nbrainstorming              95\nclosed_qa                  90\ninformation_extraction     68\nsummarization              63\ncreative_writing           39\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generating the Prompt Format","metadata":{}},{"cell_type":"code","source":"def generate_prompt(sample):\n    full_prompt =f\"\"\"<s>[INST]{sample['instruction']}\n    {f\"Here is some context: {sample['context']}\" if len(sample[\"context\"]) > 0 else None}\n    [/INST] {sample['response']}</s>\"\"\"\n    return {\"text\": full_prompt}","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.514998Z","iopub.execute_input":"2023-12-01T08:14:29.515285Z","iopub.status.idle":"2023-12-01T08:14:29.520486Z","shell.execute_reply.started":"2023-12-01T08:14:29.515259Z","shell.execute_reply":"2023-12-01T08:14:29.519537Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.521469Z","iopub.execute_input":"2023-12-01T08:14:29.521714Z","iopub.status.idle":"2023-12-01T08:14:29.533300Z","shell.execute_reply.started":"2023-12-01T08:14:29.521693Z","shell.execute_reply":"2023-12-01T08:14:29.532361Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'instruction': 'When did Virgin Australia start operating?',\n 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\",\n 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n 'category': 'closed_qa'}"},"metadata":{}}]},{"cell_type":"code","source":"print(generate_prompt(train_dataset[0]))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.534631Z","iopub.execute_input":"2023-12-01T08:14:29.534963Z","iopub.status.idle":"2023-12-01T08:14:29.544263Z","shell.execute_reply.started":"2023-12-01T08:14:29.534931Z","shell.execute_reply":"2023-12-01T08:14:29.543463Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'text': \"<s>[INST]When did Virgin Australia start operating?\\n    Here is some context: Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\\n    [/INST] Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"generated_train_dataset = train_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))\ngenerated_val_dataset = eval_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.545455Z","iopub.execute_input":"2023-12-01T08:14:29.545857Z","iopub.status.idle":"2023-12-01T08:14:29.681922Z","shell.execute_reply.started":"2023-12-01T08:14:29.545827Z","shell.execute_reply":"2023-12-01T08:14:29.680959Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15325de5ebf4a46ab4467d9f8092530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd200c366d641f99b1298b7175b507b"}},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.682975Z","iopub.execute_input":"2023-12-01T08:14:29.683272Z","iopub.status.idle":"2023-12-01T08:14:29.689622Z","shell.execute_reply.started":"2023-12-01T08:14:29.683243Z","shell.execute_reply":"2023-12-01T08:14:29.688699Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset[5][\"text\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.690865Z","iopub.execute_input":"2023-12-01T08:14:29.691161Z","iopub.status.idle":"2023-12-01T08:14:29.702697Z","shell.execute_reply.started":"2023-12-01T08:14:29.691135Z","shell.execute_reply":"2023-12-01T08:14:29.701756Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST]If I have more pieces at the time of stalemate, have I won?\\n    Here is some context: Stalemate is a situation in chess where the player whose turn it is to move is not in check and has no legal move. Stalemate results in a draw. During the endgame, stalemate is a resource that can enable the player with the inferior position to draw the game rather than lose. In more complex positions, stalemate is much rarer, usually taking the form of a swindle that succeeds only if the superior side is inattentive.[citation needed] Stalemate is also a common theme in endgame studies and other chess problems.\\n\\nThe outcome of a stalemate was standardized as a draw in the 19th century. Before this standardization, its treatment varied widely, including being deemed a win for the stalemating player, a half-win for that player, or a loss for that player; not being permitted; and resulting in the stalemated player missing a turn. Stalemate rules vary in other games of the chess family.\\n    [/INST] No. \\nStalemate is a drawn position. It doesn't matter who has captured more pieces or is in a winning position</s>\""},"metadata":{}}]},{"cell_type":"code","source":"tokenizer(generated_train_dataset[5][\"text\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.703651Z","iopub.execute_input":"2023-12-01T08:14:29.703918Z","iopub.status.idle":"2023-12-01T08:14:29.725195Z","shell.execute_reply.started":"2023-12-01T08:14:29.703896Z","shell.execute_reply":"2023-12-01T08:14:29.724501Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 1, 733, 16289, 28793, 3381, 315, 506, 680, 7769, 438, 272, 727, 302, 341, 282, 366, 380, 28725, 506, 315, 1747, 28804, 13, 2287, 4003, 349, 741, 2758, 28747, 662, 282, 366, 380, 349, 264, 4620, 297, 997, 819, 970, 272, 4385, 4636, 1527, 378, 349, 298, 2318, 349, 459, 297, 1877, 304, 659, 708, 5648, 2318, 28723, 662, 282, 366, 380, 2903, 297, 264, 3924, 28723, 6213, 272, 948, 8835, 28725, 341, 282, 366, 380, 349, 264, 3715, 369, 541, 8234, 272, 4385, 395, 272, 24797, 2840, 298, 3924, 272, 2039, 3210, 821, 6788, 28723, 560, 680, 4630, 9161, 28725, 341, 282, 366, 380, 349, 1188, 408, 283, 263, 28725, 4312, 3344, 272, 1221, 302, 264, 1719, 507, 291, 369, 9481, 28713, 865, 513, 272, 11352, 2081, 349, 297, 1061, 308, 495, 20011, 28717, 5174, 3236, 28793, 662, 282, 366, 380, 349, 835, 264, 3298, 7335, 297, 948, 8835, 7193, 304, 799, 997, 819, 4418, 28723, 13, 13, 1014, 14120, 302, 264, 341, 282, 366, 380, 403, 4787, 1332, 390, 264, 3924, 297, 272, 28705, 28740, 28774, 362, 5445, 28723, 7337, 456, 4787, 1837, 28725, 871, 5827, 20331, 12575, 28725, 2490, 1250, 24328, 264, 3108, 354, 272, 341, 282, 366, 1077, 4385, 28725, 264, 2795, 28733, 5162, 354, 369, 4385, 28725, 442, 264, 4320, 354, 369, 4385, 28745, 459, 1250, 15463, 28745, 304, 10503, 297, 272, 341, 282, 366, 601, 4385, 6925, 264, 1527, 28723, 662, 282, 366, 380, 5879, 11204, 297, 799, 3897, 302, 272, 997, 819, 2005, 28723, 13, 2287, 733, 28748, 16289, 28793, 1770, 28723, 28705, 13, 718, 282, 366, 380, 349, 264, 10421, 2840, 28723, 661, 2368, 28742, 28707, 3209, 693, 659, 13382, 680, 7769, 442, 349, 297, 264, 9821, 2840, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# LoRA Configuration","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\n\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.726301Z","iopub.execute_input":"2023-12-01T08:14:29.726976Z","iopub.status.idle":"2023-12-01T08:14:29.787855Z","shell.execute_reply.started":"2023-12-01T08:14:29.726944Z","shell.execute_reply":"2023-12-01T08:14:29.787163Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.788845Z","iopub.execute_input":"2023-12-01T08:14:29.789190Z","iopub.status.idle":"2023-12-01T08:14:29.794436Z","shell.execute_reply.started":"2023-12-01T08:14:29.789160Z","shell.execute_reply":"2023-12-01T08:14:29.793365Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n    \nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    bias=\"none\",\n    lora_dropout=0.05, \n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.795564Z","iopub.execute_input":"2023-12-01T08:14:29.795836Z","iopub.status.idle":"2023-12-01T08:14:29.808162Z","shell.execute_reply.started":"2023-12-01T08:14:29.795814Z","shell.execute_reply":"2023-12-01T08:14:29.807182Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model\n\nmodel = get_peft_model(model, lora_config)\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:29.809375Z","iopub.execute_input":"2023-12-01T08:14:29.809653Z","iopub.status.idle":"2023-12-01T08:14:30.296727Z","shell.execute_reply.started":"2023-12-01T08:14:29.809629Z","shell.execute_reply":"2023-12-01T08:14:30.295697Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"trainable params: 21260288 || all params: 3773331456 || trainable%: 0.5634354746703705\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:30.297894Z","iopub.execute_input":"2023-12-01T08:14:30.298261Z","iopub.status.idle":"2023-12-01T08:14:30.321394Z","shell.execute_reply.started":"2023-12-01T08:14:30.298225Z","shell.execute_reply":"2023-12-01T08:14:30.320194Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              )\n              (k_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              )\n              (v_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              )\n              (o_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              )\n              (up_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              )\n              (down_proj): Linear4bit(\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              )\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): Linear(\n        in_features=4096, out_features=32000, bias=False\n        (lora_dropout): ModuleDict(\n          (default): Dropout(p=0.05, inplace=False)\n        )\n        (lora_A): ModuleDict(\n          (default): Linear(in_features=4096, out_features=8, bias=False)\n        )\n        (lora_B): ModuleDict(\n          (default): Linear(in_features=8, out_features=32000, bias=False)\n        )\n        (lora_embedding_A): ParameterDict()\n        (lora_embedding_B): ParameterDict()\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF\")\n\n!huggingface-cli login --token $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:30.323792Z","iopub.execute_input":"2023-12-01T08:14:30.324124Z","iopub.status.idle":"2023-12-01T08:14:32.370848Z","shell.execute_reply.started":"2023-12-01T08:14:30.324087Z","shell.execute_reply":"2023-12-01T08:14:32.369804Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_strategy=\"steps\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    max_steps=50,\n    evaluation_strategy=\"steps\", \n    eval_steps=25,       \n    do_eval=True,               \n    report_to=\"none\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:32.372710Z","iopub.execute_input":"2023-12-01T08:14:32.373711Z","iopub.status.idle":"2023-12-01T08:14:32.397572Z","shell.execute_reply.started":"2023-12-01T08:14:32.373665Z","shell.execute_reply":"2023-12-01T08:14:32.396663Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    train_dataset=generated_train_dataset,\n    eval_dataset=generated_val_dataset,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",   \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:32.398610Z","iopub.execute_input":"2023-12-01T08:14:32.398894Z","iopub.status.idle":"2023-12-01T08:14:47.165171Z","shell.execute_reply.started":"2023-12-01T08:14:32.398869Z","shell.execute_reply":"2023-12-01T08:14:47.164098Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d29101915b47578aa26a4718267507"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b678e5f4d0c74c48b334f129a80654ca"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:14:47.166572Z","iopub.execute_input":"2023-12-01T08:14:47.166911Z","iopub.status.idle":"2023-12-01T08:46:48.281915Z","shell.execute_reply.started":"2023-12-01T08:14:47.166881Z","shell.execute_reply":"2023-12-01T08:46:48.281044Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 31:38, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.608900</td>\n      <td>1.499742</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.460600</td>\n      <td>1.461219</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=50, training_loss=1.5347483825683594, metrics={'train_runtime': 1920.7374, 'train_samples_per_second': 0.104, 'train_steps_per_second': 0.026, 'total_flos': 3426402773925888.0, 'train_loss': 1.5347483825683594, 'epoch': 0.25})"},"metadata":{}}]},{"cell_type":"code","source":"my_finetuned_model = \"mistral-7b-dolly\"\n\ntrainer.model.push_to_hub(my_finetuned_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:46:48.283122Z","iopub.execute_input":"2023-12-01T08:46:48.283812Z","iopub.status.idle":"2023-12-01T08:46:52.244310Z","shell.execute_reply.started":"2023-12-01T08:46:48.283771Z","shell.execute_reply":"2023-12-01T08:46:52.243289Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/85.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381427e9a2ac4a90b7d53b388ff5a7bc"}},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Tirendaz/mistral-7b-dolly/commit/b7db515f734542b05e0fd33cd25681f01a2a83d4', commit_message='Upload model', commit_description='', oid='b7db515f734542b05e0fd33cd25681f01a2a83d4', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}