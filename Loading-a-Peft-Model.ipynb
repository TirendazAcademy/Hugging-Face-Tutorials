{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U peft bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:55:59.384652Z","iopub.execute_input":"2023-12-01T08:55:59.385027Z","iopub.status.idle":"2023-12-01T08:56:18.337118Z","shell.execute_reply.started":"2023-12-01T08:55:59.384993Z","shell.execute_reply":"2023-12-01T08:56:18.335910Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:56:18.339238Z","iopub.execute_input":"2023-12-01T08:56:18.339580Z","iopub.status.idle":"2023-12-01T08:56:28.011464Z","shell.execute_reply.started":"2023-12-01T08:56:18.339547Z","shell.execute_reply":"2023-12-01T08:56:28.010325Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_model_id = \"Tirendaz/mistral-7b-dolly-fine-tuned\"\n\nconfig = PeftConfig.from_pretrained(peft_model_id)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-01T08:56:28.012819Z","iopub.execute_input":"2023-12-01T08:56:28.013409Z","iopub.status.idle":"2023-12-01T08:56:28.262156Z","shell.execute_reply.started":"2023-12-01T08:56:28.013368Z","shell.execute_reply":"2023-12-01T08:56:28.261201Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading adapter_config.json:   0%|          | 0.00/584 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcd0d866fd90433b8700f2e408ddb88f"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    load_in_4bit=True,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:56:28.263471Z","iopub.execute_input":"2023-12-01T08:56:28.263791Z","iopub.status.idle":"2023-12-01T08:58:39.907001Z","shell.execute_reply.started":"2023-12-01T08:56:28.263762Z","shell.execute_reply":"2023-12-01T08:58:39.905868Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963689c228d949748f4ae6fbed5b63db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1055a713434c5ea17d70f00e048f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66592310aabe44faa80ae5cc3269f3fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04e58309ede48a781054978361f63a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/5.06G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8d6b729e224fc698528b0fcdfa1d4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0074f600fed844f088c6aad426417d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec2c7c4474e4dd2b1ffafc27cec3264"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,\n                                          padding_side = \"right\",\n                                          add_eos_token = True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:58:39.910123Z","iopub.execute_input":"2023-12-01T08:58:39.910432Z","iopub.status.idle":"2023-12-01T08:58:40.881003Z","shell.execute_reply.started":"2023-12-01T08:58:39.910404Z","shell.execute_reply":"2023-12-01T08:58:40.880025Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/966 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b947f2c2a3c348dd8740e57788269f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11638c0ad0de4e08863f76b7dbae31c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b487a4d7c69c4e9fafa2054e9261a70a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88b3f91d367f4bd3bef83881a617c42c"}},"metadata":{}}]},{"cell_type":"code","source":"fine_tuned_model = PeftModel.from_pretrained(model, peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:58:40.882402Z","iopub.execute_input":"2023-12-01T08:58:40.883334Z","iopub.status.idle":"2023-12-01T08:58:42.804943Z","shell.execute_reply.started":"2023-12-01T08:58:40.883282Z","shell.execute_reply":"2023-12-01T08:58:42.804155Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)er_model.safetensors:   0%|          | 0.00/85.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"296fc3f8bf4b47b8b731e7f20faee950"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline, logging\n\nlogging.set_verbosity(logging.CRITICAL)\n\npipe = pipeline(\n    task=\"text-generation\", \n    model=fine_tuned_model, \n    tokenizer=tokenizer, \n    eos_token_id=model.config.eos_token_id,\n    max_new_tokens=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:58:42.806241Z","iopub.execute_input":"2023-12-01T08:58:42.806530Z","iopub.status.idle":"2023-12-01T08:59:01.958195Z","shell.execute_reply.started":"2023-12-01T08:58:42.806505Z","shell.execute_reply":"2023-12-01T08:59:01.957206Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"\nWhat is a Python?  Here is some context: Python is a high-level, general-purpose programming language.\n\"\"\"\npipe = pipeline(task=\"text-generation\", \n                model=fine_tuned_model, \n                tokenizer=tokenizer, \n                eos_token_id=model.config.eos_token_id, \n                max_new_tokens=100)\n\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\ngenerated = result[0]['generated_text']\nprint(generated[generated.find('[/INST]')+8:])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:59:01.959397Z","iopub.execute_input":"2023-12-01T08:59:01.959970Z","iopub.status.idle":"2023-12-01T08:59:23.184577Z","shell.execute_reply.started":"2023-12-01T08:59:01.959923Z","shell.execute_reply":"2023-12-01T08:59:23.183593Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n","output_type":"stream"},{"name":"stdout","text":"Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant whitespace. Its syntax allows programmers to express concepts in fewer lines of code than would be possible in languages such as C++ or Java. The language provides constructs intended to enable clear programming on both a small and large scale.\n\nPython is dynamically typed and garbage-collected. It has a large and comprehensive standard library. Used in a\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = \"\"\"\nPlease summarize what Linkedin does. Here is some context: LinkedIn is a business and employment-focused social media platform\n\"\"\"\npipe = pipeline(task=\"text-generation\", \n                model=fine_tuned_model, \n                tokenizer=tokenizer, \n                eos_token_id=model.config.eos_token_id, \n                max_new_tokens=100)\n\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\ngenerated = result[0]['generated_text']\nprint(generated[generated.find('[/INST]')+8:])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T08:59:23.186116Z","iopub.execute_input":"2023-12-01T08:59:23.186831Z","iopub.status.idle":"2023-12-01T08:59:35.723174Z","shell.execute_reply.started":"2023-12-01T08:59:23.186791Z","shell.execute_reply":"2023-12-01T08:59:35.722021Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"LinkedIn is a business and employment-focused social media platform. It is used for professional networking, including employers posting jobs and job seekers posting their resumes. LinkedIn was founded in 2002 and is headquartered in Sunnyvale, California. It is owned by Microsoft.\n\nLinkedIn is a business and employment-focused social media platform. It is used for professional networking, including employers posting jobs and job seekers posting their resumes.\n","output_type":"stream"}]}]}