{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>Emotion Analysis with Hugging Face</div></b>\n![](https://img.freepik.com/free-photo/medium-shot-collage-cute-kids_23-2150169774.jpg?w=1380&t=st=1696406338~exp=1696406938~hmac=9d58dea338b8f0b58b41ebd8d7f1c17cbbf408a5451974b91043a78bc6e9cb7f)\n","metadata":{}},{"cell_type":"markdown","source":"Hi guys 😀 In this notebook, we're going to cover how to perform a emotion analysis with Hugging Face. Let's get started.","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>1. Dataset Loading </div></b>","metadata":{}},{"cell_type":"markdown","source":"Let me import the dataset we're going to use in this analysis.","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:08.936555Z","iopub.execute_input":"2023-10-04T08:51:08.936920Z","iopub.status.idle":"2023-10-04T08:51:21.312283Z","shell.execute_reply.started":"2023-10-04T08:51:08.936880Z","shell.execute_reply":"2023-10-04T08:51:21.310888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nemotions = load_dataset(\"dair-ai/emotion\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:21.317915Z","iopub.execute_input":"2023-10-04T08:51:21.320411Z","iopub.status.idle":"2023-10-04T08:51:26.710692Z","shell.execute_reply.started":"2023-10-04T08:51:21.320375Z","shell.execute_reply":"2023-10-04T08:51:26.709624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>2. Understanding the Dataset </div></b>","metadata":{}},{"cell_type":"markdown","source":"Beforing training the model, let's understand our dataset.","metadata":{}},{"cell_type":"code","source":"emotions","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.712074Z","iopub.execute_input":"2023-10-04T08:51:26.713386Z","iopub.status.idle":"2023-10-04T08:51:26.722400Z","shell.execute_reply.started":"2023-10-04T08:51:26.713346Z","shell.execute_reply":"2023-10-04T08:51:26.721264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = emotions[\"train\"]\ntrain_ds","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.725508Z","iopub.execute_input":"2023-10-04T08:51:26.726309Z","iopub.status.idle":"2023-10-04T08:51:26.737576Z","shell.execute_reply.started":"2023-10-04T08:51:26.726268Z","shell.execute_reply":"2023-10-04T08:51:26.736388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.739697Z","iopub.execute_input":"2023-10-04T08:51:26.740460Z","iopub.status.idle":"2023-10-04T08:51:26.752348Z","shell.execute_reply.started":"2023-10-04T08:51:26.740371Z","shell.execute_reply":"2023-10-04T08:51:26.751216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[1]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.753572Z","iopub.execute_input":"2023-10-04T08:51:26.753919Z","iopub.status.idle":"2023-10-04T08:51:26.767677Z","shell.execute_reply.started":"2023-10-04T08:51:26.753886Z","shell.execute_reply":"2023-10-04T08:51:26.766449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.column_names","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.769064Z","iopub.execute_input":"2023-10-04T08:51:26.769494Z","iopub.status.idle":"2023-10-04T08:51:26.781384Z","shell.execute_reply.started":"2023-10-04T08:51:26.769454Z","shell.execute_reply":"2023-10-04T08:51:26.780167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.features","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.783380Z","iopub.execute_input":"2023-10-04T08:51:26.784145Z","iopub.status.idle":"2023-10-04T08:51:26.795072Z","shell.execute_reply.started":"2023-10-04T08:51:26.784107Z","shell.execute_reply":"2023-10-04T08:51:26.794382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.796173Z","iopub.execute_input":"2023-10-04T08:51:26.796613Z","iopub.status.idle":"2023-10-04T08:51:26.811091Z","shell.execute_reply.started":"2023-10-04T08:51:26.796566Z","shell.execute_reply":"2023-10-04T08:51:26.809822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[\"text\"][:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.816069Z","iopub.execute_input":"2023-10-04T08:51:26.816428Z","iopub.status.idle":"2023-10-04T08:51:26.841666Z","shell.execute_reply.started":"2023-10-04T08:51:26.816392Z","shell.execute_reply":"2023-10-04T08:51:26.840349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>3. From Dataset to Pandas </div></b>","metadata":{}},{"cell_type":"markdown","source":"Let's dive into the dataset by converting Dataset to Pandas.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nemotions.set_format(type=\"pandas\")\ndf=emotions[\"train\"][:]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.843653Z","iopub.execute_input":"2023-10-04T08:51:26.844260Z","iopub.status.idle":"2023-10-04T08:51:26.897714Z","shell.execute_reply.started":"2023-10-04T08:51:26.844221Z","shell.execute_reply":"2023-10-04T08:51:26.896714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_int2str(row):\n    return emotions[\"train\"].features[\"label\"].int2str(row)\n\ndf[\"label_name\"] = df[\"label\"].apply(label_int2str)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.898932Z","iopub.execute_input":"2023-10-04T08:51:26.899846Z","iopub.status.idle":"2023-10-04T08:51:26.939675Z","shell.execute_reply.started":"2023-10-04T08:51:26.899799Z","shell.execute_reply":"2023-10-04T08:51:26.938523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>4. Data Visualization </div></b>","metadata":{}},{"cell_type":"markdown","source":"Let me draw a few graphs to understand our data set.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf[\"label_name\"].value_counts(ascending=True).plot.barh()\nplt.title(\"Frequency of Classes\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:26.941255Z","iopub.execute_input":"2023-10-04T08:51:26.941902Z","iopub.status.idle":"2023-10-04T08:51:27.251199Z","shell.execute_reply.started":"2023-10-04T08:51:26.941864Z","shell.execute_reply":"2023-10-04T08:51:27.250321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\ndf.boxplot(\"Words Per Tweet\", by=\"label_name\", grid = False, showfliers = False,\n          color = \"black\")\nplt.suptitle(\"\")\nplt.xlabel(\"\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.252371Z","iopub.execute_input":"2023-10-04T08:51:27.253252Z","iopub.status.idle":"2023-10-04T08:51:27.661333Z","shell.execute_reply.started":"2023-10-04T08:51:27.253219Z","shell.execute_reply":"2023-10-04T08:51:27.660344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions.reset_format()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.662679Z","iopub.execute_input":"2023-10-04T08:51:27.663715Z","iopub.status.idle":"2023-10-04T08:51:27.670103Z","shell.execute_reply.started":"2023-10-04T08:51:27.663676Z","shell.execute_reply":"2023-10-04T08:51:27.668944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>5. Data Preprocessing </div></b>","metadata":{}},{"cell_type":"markdown","source":"In this section, we're going to perform data preprocessing. First, let's take a look at three tokenization techniques: Character tokenization, word tokenization and subword tokenization. Let's dive in!","metadata":{}},{"cell_type":"markdown","source":"## Character Tokenization","metadata":{}},{"cell_type":"code","source":"text = \"It is fun to work with NLP using HuggingFace.\"\n\ntokenized_text = list(text)\nprint(tokenized_text)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.671955Z","iopub.execute_input":"2023-10-04T08:51:27.672375Z","iopub.status.idle":"2023-10-04T08:51:27.685204Z","shell.execute_reply.started":"2023-10-04T08:51:27.672341Z","shell.execute_reply":"2023-10-04T08:51:27.683819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\nprint(token2idx)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.686628Z","iopub.execute_input":"2023-10-04T08:51:27.688544Z","iopub.status.idle":"2023-10-04T08:51:27.697933Z","shell.execute_reply.started":"2023-10-04T08:51:27.688506Z","shell.execute_reply":"2023-10-04T08:51:27.696860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids=[token2idx[token] for token in tokenized_text]\nprint(input_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.699612Z","iopub.execute_input":"2023-10-04T08:51:27.700554Z","iopub.status.idle":"2023-10-04T08:51:27.710531Z","shell.execute_reply.started":"2023-10-04T08:51:27.700520Z","shell.execute_reply":"2023-10-04T08:51:27.709502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How to work one-hot encoding?","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({\"name\":[\"can\", \"efe\",\"ada\"],\n                  \"label\":[0,1,2]})\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.711883Z","iopub.execute_input":"2023-10-04T08:51:27.712787Z","iopub.status.idle":"2023-10-04T08:51:27.726019Z","shell.execute_reply.started":"2023-10-04T08:51:27.712753Z","shell.execute_reply":"2023-10-04T08:51:27.724572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(df, dtype=int)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.728025Z","iopub.execute_input":"2023-10-04T08:51:27.729045Z","iopub.status.idle":"2023-10-04T08:51:27.745979Z","shell.execute_reply.started":"2023-10-04T08:51:27.729007Z","shell.execute_reply":"2023-10-04T08:51:27.744877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One-hot encoding with Torch","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\n# Converting inputs into tensor\ninput_ids = torch.tensor(input_ids)\n\none_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\none_hot_encodings.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:27.747722Z","iopub.execute_input":"2023-10-04T08:51:27.748208Z","iopub.status.idle":"2023-10-04T08:51:32.924864Z","shell.execute_reply.started":"2023-10-04T08:51:27.748171Z","shell.execute_reply":"2023-10-04T08:51:32.923739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Token:{tokenized_text[0]}\")\nprint(f\"Tensor index: {input_ids[0]}\")\nprint(f\"One-hot: {one_hot_encodings[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:32.926879Z","iopub.execute_input":"2023-10-04T08:51:32.927928Z","iopub.status.idle":"2023-10-04T08:51:32.952225Z","shell.execute_reply.started":"2023-10-04T08:51:32.927888Z","shell.execute_reply":"2023-10-04T08:51:32.951073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word Tokenization ","metadata":{}},{"cell_type":"code","source":"tokenized_text = text.split()\nprint(tokenized_text)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:32.954306Z","iopub.execute_input":"2023-10-04T08:51:32.955253Z","iopub.status.idle":"2023-10-04T08:51:32.961646Z","shell.execute_reply.started":"2023-10-04T08:51:32.955214Z","shell.execute_reply":"2023-10-04T08:51:32.960526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Subword Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:32.963192Z","iopub.execute_input":"2023-10-04T08:51:32.963908Z","iopub.status.idle":"2023-10-04T08:51:36.636823Z","shell.execute_reply.started":"2023-10-04T08:51:32.963875Z","shell.execute_reply":"2023-10-04T08:51:36.635896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer\n\ndistbert_tokenize=DistilBertTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.638273Z","iopub.execute_input":"2023-10-04T08:51:36.638936Z","iopub.status.idle":"2023-10-04T08:51:36.737645Z","shell.execute_reply.started":"2023-10-04T08:51:36.638903Z","shell.execute_reply":"2023-10-04T08:51:36.736587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How to work with Tokenizer","metadata":{}},{"cell_type":"code","source":"encoded_text = tokenizer(text)\nprint(encoded_text)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.739077Z","iopub.execute_input":"2023-10-04T08:51:36.739449Z","iopub.status.idle":"2023-10-04T08:51:36.753960Z","shell.execute_reply.started":"2023-10-04T08:51:36.739415Z","shell.execute_reply":"2023-10-04T08:51:36.752979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.755456Z","iopub.execute_input":"2023-10-04T08:51:36.756327Z","iopub.status.idle":"2023-10-04T08:51:36.765244Z","shell.execute_reply.started":"2023-10-04T08:51:36.756293Z","shell.execute_reply":"2023-10-04T08:51:36.764382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_string(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.770228Z","iopub.execute_input":"2023-10-04T08:51:36.771011Z","iopub.status.idle":"2023-10-04T08:51:36.780618Z","shell.execute_reply.started":"2023-10-04T08:51:36.770981Z","shell.execute_reply":"2023-10-04T08:51:36.779602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attributes of Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.781850Z","iopub.execute_input":"2023-10-04T08:51:36.782437Z","iopub.status.idle":"2023-10-04T08:51:36.791884Z","shell.execute_reply.started":"2023-10-04T08:51:36.782406Z","shell.execute_reply":"2023-10-04T08:51:36.790885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.model_max_length","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.793043Z","iopub.execute_input":"2023-10-04T08:51:36.793596Z","iopub.status.idle":"2023-10-04T08:51:36.804287Z","shell.execute_reply.started":"2023-10-04T08:51:36.793565Z","shell.execute_reply":"2023-10-04T08:51:36.803308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing the entire dataset","metadata":{}},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.806057Z","iopub.execute_input":"2023-10-04T08:51:36.806968Z","iopub.status.idle":"2023-10-04T08:51:36.815117Z","shell.execute_reply.started":"2023-10-04T08:51:36.806939Z","shell.execute_reply":"2023-10-04T08:51:36.814232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How to work tokenizer on our some data:\nprint(tokenize(emotions[\"train\"][:2]))","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.816137Z","iopub.execute_input":"2023-10-04T08:51:36.816643Z","iopub.status.idle":"2023-10-04T08:51:36.831399Z","shell.execute_reply.started":"2023-10-04T08:51:36.816605Z","shell.execute_reply":"2023-10-04T08:51:36.830129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True,\n                               batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:36.833001Z","iopub.execute_input":"2023-10-04T08:51:36.833859Z","iopub.status.idle":"2023-10-04T08:51:38.804842Z","shell.execute_reply.started":"2023-10-04T08:51:36.833821Z","shell.execute_reply":"2023-10-04T08:51:38.803780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Padding","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer = tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:38.806175Z","iopub.execute_input":"2023-10-04T08:51:38.807070Z","iopub.status.idle":"2023-10-04T08:51:51.549872Z","shell.execute_reply.started":"2023-10-04T08:51:38.807036Z","shell.execute_reply":"2023-10-04T08:51:51.548807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's take a look at the columns of the dataset\nemotions_encoded[\"train\"].column_names","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:51.551411Z","iopub.execute_input":"2023-10-04T08:51:51.552097Z","iopub.status.idle":"2023-10-04T08:51:51.558276Z","shell.execute_reply.started":"2023-10-04T08:51:51.552063Z","shell.execute_reply":"2023-10-04T08:51:51.557290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>6. Model Training </div></b>","metadata":{}},{"cell_type":"markdown","source":"In this section, we're going to load our BERT-based model, set metrics and training arguments and then train our model.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nnum_labels = 6\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel=AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n         num_labels = num_labels).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:51:51.559658Z","iopub.execute_input":"2023-10-04T08:51:51.560737Z","iopub.status.idle":"2023-10-04T08:52:04.624240Z","shell.execute_reply.started":"2023-10-04T08:51:51.560701Z","shell.execute_reply":"2023-10-04T08:52:04.623164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"!pip install -q evaluate","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:52:04.625758Z","iopub.execute_input":"2023-10-04T08:52:04.626137Z","iopub.status.idle":"2023-10-04T08:52:14.390425Z","shell.execute_reply.started":"2023-10-04T08:52:04.626099Z","shell.execute_reply":"2023-10-04T08:52:14.389216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, \n                           references = labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:52:14.394109Z","iopub.execute_input":"2023-10-04T08:52:14.394569Z","iopub.status.idle":"2023-10-04T08:52:17.291579Z","shell.execute_reply.started":"2023-10-04T08:52:14.394526Z","shell.execute_reply":"2023-10-04T08:52:17.290472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logging to HuggingFace","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:52:48.096218Z","iopub.execute_input":"2023-10-04T08:52:48.096589Z","iopub.status.idle":"2023-10-04T08:52:48.133250Z","shell.execute_reply.started":"2023-10-04T08:52:48.096561Z","shell.execute_reply":"2023-10-04T08:52:48.132239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting Training Arguments","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"distilbert-emotion\",\n    num_train_epochs = 2, \n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy = \"epoch\",\n    load_best_model_at_end = True,\n    push_to_hub = True,\n    report_to = \"none\"    \n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:52:56.236666Z","iopub.execute_input":"2023-10-04T08:52:56.237768Z","iopub.status.idle":"2023-10-04T08:52:56.253535Z","shell.execute_reply.started":"2023-10-04T08:52:56.237731Z","shell.execute_reply":"2023-10-04T08:52:56.252637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model = model,\n    args = training_args,\n    compute_metrics = compute_metrics,\n    train_dataset = emotions_encoded[\"train\"],\n    eval_dataset = emotions_encoded[\"validation\"],\n    tokenizer = tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:52:58.754877Z","iopub.execute_input":"2023-10-04T08:52:58.755236Z","iopub.status.idle":"2023-10-04T08:52:58.863247Z","shell.execute_reply.started":"2023-10-04T08:52:58.755210Z","shell.execute_reply":"2023-10-04T08:52:58.862125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:53:00.925256Z","iopub.execute_input":"2023-10-04T08:53:00.926415Z","iopub.status.idle":"2023-10-04T08:54:58.101922Z","shell.execute_reply.started":"2023-10-04T08:53:00.926379Z","shell.execute_reply":"2023-10-04T08:54:58.100883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>7. Model Evaluation </div></b>","metadata":{}},{"cell_type":"markdown","source":"In this section, we're going to look at the performance of our model.","metadata":{}},{"cell_type":"markdown","source":"## Predicting the validation dataset","metadata":{}},{"cell_type":"code","source":"preds_output = trainer.predict(emotions_encoded[\"validation\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:54:58.104091Z","iopub.execute_input":"2023-10-04T08:54:58.104824Z","iopub.status.idle":"2023-10-04T08:55:00.430976Z","shell.execute_reply.started":"2023-10-04T08:54:58.104786Z","shell.execute_reply":"2023-10-04T08:55:00.429928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_output.metrics","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:00.432226Z","iopub.execute_input":"2023-10-04T08:55:00.433258Z","iopub.status.idle":"2023-10-04T08:55:00.440038Z","shell.execute_reply.started":"2023-10-04T08:55:00.433221Z","shell.execute_reply":"2023-10-04T08:55:00.439176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n\ny_preds = np.argmax(preds_output.predictions, axis=1)\n\ndef plot_confusion_matrix(y_preds, y_true, labels):\n    cm = confusion_matrix(y_true, y_preds, normalize = \"true\")\n    fig, ax = plt.subplots(figsize=(6,6))\n    disp = ConfusionMatrixDisplay(confusion_matrix = cm, \n                                 display_labels=labels)\n    disp.plot(cmap=\"Blues\", values_format = \".2f\", ax = ax,\n             colorbar=False)\n    plt.title(\"Normalized confusion matrix\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:00.442989Z","iopub.execute_input":"2023-10-04T08:55:00.443521Z","iopub.status.idle":"2023-10-04T08:55:00.451229Z","shell.execute_reply.started":"2023-10-04T08:55:00.443496Z","shell.execute_reply":"2023-10-04T08:55:00.450438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid = np.array(emotions_encoded[\"validation\"][\"label\"])\nlabels = emotions[\"train\"].features[\"label\"].names","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:00.452806Z","iopub.execute_input":"2023-10-04T08:55:00.453601Z","iopub.status.idle":"2023-10-04T08:55:00.465999Z","shell.execute_reply.started":"2023-10-04T08:55:00.453567Z","shell.execute_reply":"2023-10-04T08:55:00.465126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(y_preds, y_valid, labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:00.467581Z","iopub.execute_input":"2023-10-04T08:55:00.467915Z","iopub.status.idle":"2023-10-04T08:55:00.764687Z","shell.execute_reply.started":"2023-10-04T08:55:00.467880Z","shell.execute_reply":"2023-10-04T08:55:00.763817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:00.766330Z","iopub.execute_input":"2023-10-04T08:55:00.766956Z","iopub.status.idle":"2023-10-04T08:55:03.728802Z","shell.execute_reply.started":"2023-10-04T08:55:00.766924Z","shell.execute_reply":"2023-10-04T08:55:03.727878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:15px;background-color:#850E35;color:white;border-radius:2px;font-size:110%;text-align: center'>8. Model Prediction </div></b>","metadata":{}},{"cell_type":"markdown","source":"In this section, we're first going to get a new text and predict the label of it with our model.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nmodel_id = \"Tirendaz/distilbert-emotion\"\nclassifier = pipeline(\"text-classification\", model= model_id)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:03.732916Z","iopub.execute_input":"2023-10-04T08:55:03.735473Z","iopub.status.idle":"2023-10-04T08:55:11.264751Z","shell.execute_reply.started":"2023-10-04T08:55:03.735434Z","shell.execute_reply":"2023-10-04T08:55:11.263641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_text=\"I watched a movie yesterday. It was really good.\"","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:11.266541Z","iopub.execute_input":"2023-10-04T08:55:11.266946Z","iopub.status.idle":"2023-10-04T08:55:11.271486Z","shell.execute_reply.started":"2023-10-04T08:55:11.266908Z","shell.execute_reply":"2023-10-04T08:55:11.270462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=classifier(custom_text, return_all_scores = True)\npreds_df = pd.DataFrame(preds[0])\nplt.bar(labels, 100*preds_df[\"score\"])\nplt.title(f'\"{custom_text}\"')\nplt.ylabel(\"Class probability (%)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:55:11.274815Z","iopub.execute_input":"2023-10-04T08:55:11.275586Z","iopub.status.idle":"2023-10-04T08:55:11.772915Z","shell.execute_reply.started":"2023-10-04T08:55:11.275547Z","shell.execute_reply":"2023-10-04T08:55:11.772015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thanks for reading! If you enjoyed this notebook, don't forget to upvote** 👍\n\n*Let's connect* [YouTube](http://youtube.com/tirendazacademy) | [Medium](http://tirendazacademy.medium.com) | [X](http://x.com/tirendazacademy) | [Linkedin](https://www.linkedin.com/in/tirendaz-academy) 😎\n\n## Resource\n\n- [NLP with Transformers](https://github.com/nlp-with-transformers/notebooks/blob/main/02_classification.ipynb)","metadata":{}}]}