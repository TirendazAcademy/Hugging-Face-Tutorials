{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U peft bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:17:12.411678Z","iopub.execute_input":"2023-11-29T09:17:12.411977Z","iopub.status.idle":"2023-11-29T09:17:15.377273Z","shell.execute_reply.started":"2023-11-29T09:17:12.411951Z","shell.execute_reply":"2023-11-29T09:17:15.376428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the identifier for the pre-trained Peft model\npeft_model_id = \"Tirendaz/mistral-7b-dolly\"\n\n# Load the configuration for the Peft model\nconfig = PeftConfig.from_pretrained(peft_model_id)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T09:17:15.424269Z","iopub.execute_input":"2023-11-29T09:17:15.425140Z","iopub.status.idle":"2023-11-29T09:17:15.718490Z","shell.execute_reply.started":"2023-11-29T09:17:15.425110Z","shell.execute_reply":"2023-11-29T09:17:15.717494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\n# Load the base model for Causal Language Modeling with specified settings\n# - Use AutoModelForCausalLM to load the model.\n# - Set return_dict=True to enable returning model outputs as dictionaries.\n# - Enable 4-bit weight quantization with load_in_4bit=True.\n# - Set device_map='auto' to automatically allocate the model on available devices.\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    load_in_4bit=True,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:17:18.822150Z","iopub.execute_input":"2023-11-29T09:17:18.822889Z","iopub.status.idle":"2023-11-29T09:21:21.762162Z","shell.execute_reply.started":"2023-11-29T09:17:18.822849Z","shell.execute_reply":"2023-11-29T09:21:21.761131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the tokenizer associated with the base model\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,\n                                          padding_side = \"right\",\n                                          add_eos_token = True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:22:01.813302Z","iopub.execute_input":"2023-11-29T09:22:01.813695Z","iopub.status.idle":"2023-11-29T09:22:02.955469Z","shell.execute_reply.started":"2023-11-29T09:22:01.813662Z","shell.execute_reply":"2023-11-29T09:22:02.954636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the PeftModel, which applies the Peft (Perturbed Embeddings for Few-shot Text Classification) method\n# to the base model, using the specified pre-trained Peft model identifier\nfine_tuned_model = PeftModel.from_pretrained(model, peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:22:56.062380Z","iopub.execute_input":"2023-11-29T09:22:56.062769Z","iopub.status.idle":"2023-11-29T09:23:08.375158Z","shell.execute_reply.started":"2023-11-29T09:22:56.062736Z","shell.execute_reply":"2023-11-29T09:23:08.374325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, logging\n\nlogging.set_verbosity(logging.CRITICAL)\n\npipe_finetuned = pipeline(task=\"text-generation\", \n                          model=fine_tuned_model, \n                          tokenizer=tokenizer, \n                          eos_token_id=model.config.eos_token_id,\n                          max_new_tokens=100)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:26:49.421714Z","iopub.execute_input":"2023-11-29T09:26:49.422568Z","iopub.status.idle":"2023-11-29T09:26:49.427990Z","shell.execute_reply.started":"2023-11-29T09:26:49.422531Z","shell.execute_reply":"2023-11-29T09:26:49.427083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"\n<s>[INST] What is a Python?  Here is some context: Python is a high-level, general-purpose programming language. [/INST] \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:38:27.221776Z","iopub.execute_input":"2023-11-29T09:38:27.222198Z","iopub.status.idle":"2023-11-29T09:38:27.226723Z","shell.execute_reply.started":"2023-11-29T09:38:27.222166Z","shell.execute_reply":"2023-11-29T09:38:27.225710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pipe_finetuned(\n    prompt, \n    do_sample=True,\n    max_new_tokens=100, \n)\nprint(result[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-11-29T09:38:29.421007Z","iopub.execute_input":"2023-11-29T09:38:29.421387Z","iopub.status.idle":"2023-11-29T09:38:39.445412Z","shell.execute_reply.started":"2023-11-29T09:38:29.421359Z","shell.execute_reply":"2023-11-29T09:38:39.444445Z"},"trusted":true},"execution_count":null,"outputs":[]}]}